{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\cvenkatanagasatya\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import RNN, GRU, LSTM, Dense, Input, Embedding, Dropout, Activation, concatenate\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "dimensions = 200\n",
    "num_samples = 10000\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Definitely!</td>\n",
       "      <td>తప్పకుండా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He hung up.</td>\n",
       "      <td>అతను పెట్టేసాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ran home.</td>\n",
       "      <td>నేను ఇంటికి పరిగెత్తాను</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>మేము ఎవరము ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are you mad?</td>\n",
       "      <td>కోపమొచ్చిందా ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Can you tell me where the nearest bus stop is?</td>\n",
       "      <td>దగ్గరలో వున్న బస్ స్టాప్ ఎక్కడో కొంచెం చెప్తావా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I've made a mistake, though I didn't intend to.</td>\n",
       "      <td>నేనో పొరపాటు చేసాను, కావాలని కాకపోయినా.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>It's going to take all afternoon and maybe more.</td>\n",
       "      <td>మధ్యాహ్నం మొత్తం లేదా ఇంకా ఎక్కువ సమయం పట్టొచ్చు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>My father often falls asleep while watching te...</td>\n",
       "      <td>మా నాన్న దురదర్శిని చూస్తూనే నిద్ర పోతాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>He has two pencils. One is long and the other ...</td>\n",
       "      <td>తన దగ్గర రెండు పెన్సిళ్ళు వున్నాయి. ఒకటి పొడుగ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   eng  \\\n",
       "0                                          Definitely!   \n",
       "1                                          He hung up.   \n",
       "2                                          I ran home.   \n",
       "3                                          Who are we?   \n",
       "4                                         Are you mad?   \n",
       "..                                                 ...   \n",
       "129     Can you tell me where the nearest bus stop is?   \n",
       "130    I've made a mistake, though I didn't intend to.   \n",
       "131   It's going to take all afternoon and maybe more.   \n",
       "132  My father often falls asleep while watching te...   \n",
       "133  He has two pencils. One is long and the other ...   \n",
       "\n",
       "                                                   tel  \n",
       "0                                            తప్పకుండా  \n",
       "1                                      అతను పెట్టేసాడు  \n",
       "2                              నేను ఇంటికి పరిగెత్తాను  \n",
       "3                                         మేము ఎవరము ?  \n",
       "4                                       కోపమొచ్చిందా ?  \n",
       "..                                                 ...  \n",
       "129    దగ్గరలో వున్న బస్ స్టాప్ ఎక్కడో కొంచెం చెప్తావా  \n",
       "130            నేనో పొరపాటు చేసాను, కావాలని కాకపోయినా.  \n",
       "131   మధ్యాహ్నం మొత్తం లేదా ఇంకా ఎక్కువ సమయం పట్టొచ్చు  \n",
       "132          మా నాన్న దురదర్శిని చూస్తూనే నిద్ర పోతాడు  \n",
       "133  తన దగ్గర రెండు పెన్సిళ్ళు వున్నాయి. ఒకటి పొడుగ...  \n",
       "\n",
       "[134 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_table('tel.txt', names=['eng', 'tel'], index_col=False)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng = lines.eng.apply(lambda x : x.lower())\n",
    "lines.tel = lines.tel.apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "lines.eng = [x for x in lines.eng if x not in string.punctuation]\n",
    "lines.tel = [x for x in lines.tel if x not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definitely!</td>\n",
       "      <td>తప్పకుండా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he hung up.</td>\n",
       "      <td>అతను పెట్టేసాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ran home.</td>\n",
       "      <td>నేను ఇంటికి పరిగెత్తాను</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are we?</td>\n",
       "      <td>మేము ఎవరము ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are you mad?</td>\n",
       "      <td>కోపమొచ్చిందా ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eng                      tel\n",
       "0   definitely!                తప్పకుండా\n",
       "1   he hung up.          అతను పెట్టేసాడు\n",
       "2   i ran home.  నేను ఇంటికి పరిగెత్తాను\n",
       "3   who are we?             మేము ఎవరము ?\n",
       "4  are you mad?           కోపమొచ్చిందా ?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.tel = lines.tel.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definitely!</td>\n",
       "      <td>START_ తప్పకుండా _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he hung up.</td>\n",
       "      <td>START_ అతను పెట్టేసాడు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ran home.</td>\n",
       "      <td>START_ నేను ఇంటికి పరిగెత్తాను _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are we?</td>\n",
       "      <td>START_ మేము ఎవరము ? _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are you mad?</td>\n",
       "      <td>START_ కోపమొచ్చిందా ? _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eng                                  tel\n",
       "0   definitely!                START_ తప్పకుండా _END\n",
       "1   he hung up.          START_ అతను పెట్టేసాడు _END\n",
       "2   i ran home.  START_ నేను ఇంటికి పరిగెత్తాను _END\n",
       "3   who are we?             START_ మేము ఎవరము ? _END\n",
       "4  are you mad?           START_ కోపమొచ్చిందా ? _END"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_tel_words=set()\n",
    "for fr in lines.tel:\n",
    "    for word in fr.split():\n",
    "        if word not in all_tel_words:\n",
    "            all_tel_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 403)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len( all_tel_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_tel_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_tel_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 403)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_eng_length = []\n",
    "for word in lines.eng:\n",
    "    #print(word)\n",
    "    max_eng_length.append(len(word.split(\" \")))\n",
    "    \n",
    "np.max(max_eng_length)\n",
    "\n",
    "\n",
    "max_tel_length = []\n",
    "for tel in lines.tel:\n",
    "    #print(word)\n",
    "    max_tel_length.append(len(tel.split(\" \")))\n",
    "    \n",
    "np.max(max_tel_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(max_eng_length), np.max(max_tel_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index['definitely!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer(filters='')\n",
    "eng_tokenizer.fit_on_texts(lines.eng)\n",
    "\n",
    "english_index = eng_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_tokenizer = Tokenizer(filters='')\n",
    "tel_tokenizer.fit_on_texts(lines.tel)\n",
    "\n",
    "telugu_index = tel_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(telugu_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('',embedding_file), encoding='utf8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cc.te.300.vec', 'rb') as ins:\n",
    "    telugu_vectors = []\n",
    "    for line in ins:\n",
    "        telugu_vectors.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://fasttext.cc/docs/en/english-vectors.html\n",
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telugu_vectors = load_vectors('cc.te.300.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_num_words = len(all_eng_words)+1\n",
    "english_embedding_matrix = np.zeros((eng_num_words, 300))\n",
    "for word, i in english_index.items():\n",
    "    if i > eng_num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        english_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_num_words = len(all_tel_words)+1\n",
    "telugu_embedding_matrix = np.zeros((tel_num_words, 300))\n",
    "for word, i in telugu_index.items():\n",
    "    if i > tel_num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        telugu_embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_embedding_layer = Embedding(\n",
    "    eng_num_words,\n",
    "    300,\n",
    "    weights=[english_embedding_matrix],\n",
    "    input_length = num_encoder_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "telugu_embedding_layer = Embedding(\n",
    "    tel_num_words,\n",
    "    300,\n",
    "    weights=[telugu_embedding_matrix],\n",
    "    input_length = num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(lines.eng), 13),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(lines.tel), 12),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(lines.tel), 12, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "\n",
    "predict_encoder_data = np.zeros(\n",
    "    (1, 13),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.tel)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 13), (134, 12, 403))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [123., 140., 340.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rough \n",
    "for i, (eng, tel) in enumerate(zip(lines.eng, lines.tel)):\n",
    "    for t, word in enumerate(eng.split()):\n",
    "        #print(t)\n",
    "        encoder_input_data[i,t] = w2i[word]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data[1,2] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 6., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "en_x=  english_embedding_layer(encoder_inputs)\n",
    "encoder = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dex=  Embedding(num_decoder_tokens, 50)\n",
    "final_dex= dex(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 383, 300)     115200      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     20150       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50), (None,  70200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 403)    20553       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 246,303\n",
      "Trainable params: 246,303\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131 samples, validate on 3 samples\n",
      "Epoch 1/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1369 - acc: 0.2144 - val_loss: 6.3942 - val_acc: 0.0833\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.1220 - acc: 0.2150 - val_loss: 6.2527 - val_acc: 0.0833\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.1111 - acc: 0.2265 - val_loss: 6.0333 - val_acc: 0.0833\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1037 - acc: 0.2214 - val_loss: 6.3558 - val_acc: 0.0833\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0935 - acc: 0.2265 - val_loss: 6.1966 - val_acc: 0.0833\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.0821 - acc: 0.2392 - val_loss: 5.9158 - val_acc: 0.0833\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 1.0667 - acc: 0.2411 - val_loss: 6.3953 - val_acc: 0.0833\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 1.0577 - acc: 0.2411 - val_loss: 5.9963 - val_acc: 0.0833\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 1.0557 - acc: 0.2405 - val_loss: 6.2586 - val_acc: 0.0833\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 1.0377 - acc: 0.2519 - val_loss: 6.1129 - val_acc: 0.0833\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 1.0224 - acc: 0.2595 - val_loss: 6.2251 - val_acc: 0.0833\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 1.0158 - acc: 0.2602 - val_loss: 6.0340 - val_acc: 0.0833\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 1.0036 - acc: 0.2672 - val_loss: 6.1598 - val_acc: 0.0833\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.9925 - acc: 0.2691 - val_loss: 5.9752 - val_acc: 0.0833\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.9833 - acc: 0.2805 - val_loss: 6.0422 - val_acc: 0.0833\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.9727 - acc: 0.2729 - val_loss: 6.3811 - val_acc: 0.0833\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.9670 - acc: 0.2767 - val_loss: 6.1092 - val_acc: 0.0833\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.9532 - acc: 0.2837 - val_loss: 5.9922 - val_acc: 0.0833\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.9437 - acc: 0.2850 - val_loss: 6.0935 - val_acc: 0.0833\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.9313 - acc: 0.2958 - val_loss: 6.2449 - val_acc: 0.0833\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.9220 - acc: 0.2952 - val_loss: 6.1082 - val_acc: 0.0833\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.9096 - acc: 0.2996 - val_loss: 6.1216 - val_acc: 0.0833\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.9029 - acc: 0.3028 - val_loss: 6.5385 - val_acc: 0.0833\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.8926 - acc: 0.3028 - val_loss: 5.9311 - val_acc: 0.0833\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.8888 - acc: 0.3047 - val_loss: 6.6543 - val_acc: 0.0833\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.8746 - acc: 0.2996 - val_loss: 6.3647 - val_acc: 0.0833\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.8628 - acc: 0.3104 - val_loss: 6.3681 - val_acc: 0.0833\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.8525 - acc: 0.3155 - val_loss: 6.4536 - val_acc: 0.0833\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.8435 - acc: 0.3174 - val_loss: 6.4131 - val_acc: 0.0833\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.8330 - acc: 0.3251 - val_loss: 6.5826 - val_acc: 0.0833\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.8269 - acc: 0.3276 - val_loss: 6.2815 - val_acc: 0.0833\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.8152 - acc: 0.3295 - val_loss: 6.2307 - val_acc: 0.0833\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.8065 - acc: 0.3359 - val_loss: 6.2642 - val_acc: 0.0833\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.7959 - acc: 0.3352 - val_loss: 6.3323 - val_acc: 0.0833\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.7842 - acc: 0.3391 - val_loss: 6.4141 - val_acc: 0.0833\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.7740 - acc: 0.3486 - val_loss: 6.1173 - val_acc: 0.0833\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.7676 - acc: 0.3461 - val_loss: 6.4478 - val_acc: 0.0833\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.7602 - acc: 0.3499 - val_loss: 6.0433 - val_acc: 0.0833\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.7522 - acc: 0.3524 - val_loss: 6.3725 - val_acc: 0.0833\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.7365 - acc: 0.3569 - val_loss: 6.4665 - val_acc: 0.0833\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.7313 - acc: 0.3575 - val_loss: 6.1853 - val_acc: 0.0833\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 0.7236 - acc: 0.3575 - val_loss: 6.3695 - val_acc: 0.0833\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.7145 - acc: 0.3594 - val_loss: 6.2841 - val_acc: 0.0833\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.7066 - acc: 0.3581 - val_loss: 6.3091 - val_acc: 0.0833\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.6919 - acc: 0.3626 - val_loss: 6.2852 - val_acc: 0.0833\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.6991 - acc: 0.3645 - val_loss: 6.3904 - val_acc: 0.0833\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.6735 - acc: 0.3747 - val_loss: 6.2960 - val_acc: 0.0833\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6649 - acc: 0.3734 - val_loss: 6.3364 - val_acc: 0.0833\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.6566 - acc: 0.3766 - val_loss: 6.8523 - val_acc: 0.0833\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.6530 - acc: 0.3772 - val_loss: 6.3463 - val_acc: 0.0833\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6435 - acc: 0.3779 - val_loss: 6.1782 - val_acc: 0.0833\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6333 - acc: 0.3823 - val_loss: 6.5223 - val_acc: 0.0833\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6257 - acc: 0.3842 - val_loss: 6.5520 - val_acc: 0.0833\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6237 - acc: 0.3810 - val_loss: 6.3139 - val_acc: 0.0833\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6145 - acc: 0.3887 - val_loss: 6.4319 - val_acc: 0.0833\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6040 - acc: 0.3855 - val_loss: 6.6202 - val_acc: 0.0833\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5924 - acc: 0.3931 - val_loss: 6.2009 - val_acc: 0.0833\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5961 - acc: 0.3880 - val_loss: 6.4369 - val_acc: 0.0833\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5792 - acc: 0.3938 - val_loss: 6.7217 - val_acc: 0.0833\n",
      "Epoch 60/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5726 - acc: 0.3944 - val_loss: 6.7492 - val_acc: 0.0833\n",
      "Epoch 61/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5636 - acc: 0.3957 - val_loss: 6.7770 - val_acc: 0.0833\n",
      "Epoch 62/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5549 - acc: 0.4020 - val_loss: 6.6077 - val_acc: 0.0833\n",
      "Epoch 63/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5545 - acc: 0.4001 - val_loss: 6.8413 - val_acc: 0.0833\n",
      "Epoch 64/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5492 - acc: 0.3995 - val_loss: 6.5045 - val_acc: 0.0833\n",
      "Epoch 65/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.5368 - acc: 0.4039 - val_loss: 6.5829 - val_acc: 0.0833\n",
      "Epoch 66/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5287 - acc: 0.4059 - val_loss: 6.6177 - val_acc: 0.0833\n",
      "Epoch 67/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5182 - acc: 0.4065 - val_loss: 6.8118 - val_acc: 0.0833\n",
      "Epoch 68/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5122 - acc: 0.4084 - val_loss: 6.5443 - val_acc: 0.0833\n",
      "Epoch 69/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5042 - acc: 0.4084 - val_loss: 6.9627 - val_acc: 0.0833\n",
      "Epoch 70/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5072 - acc: 0.4071 - val_loss: 6.7364 - val_acc: 0.0833\n",
      "Epoch 71/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4939 - acc: 0.4109 - val_loss: 6.9821 - val_acc: 0.0833\n",
      "Epoch 72/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4842 - acc: 0.4116 - val_loss: 6.7054 - val_acc: 0.0833\n",
      "Epoch 73/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4842 - acc: 0.4116 - val_loss: 7.0684 - val_acc: 0.0833\n",
      "Epoch 74/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4727 - acc: 0.4141 - val_loss: 7.1488 - val_acc: 0.0833\n",
      "Epoch 75/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4694 - acc: 0.4109 - val_loss: 7.0921 - val_acc: 0.0833\n",
      "Epoch 76/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4661 - acc: 0.4141 - val_loss: 6.8831 - val_acc: 0.0833\n",
      "Epoch 77/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4510 - acc: 0.4167 - val_loss: 6.8349 - val_acc: 0.0833\n",
      "Epoch 78/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4501 - acc: 0.4173 - val_loss: 7.0473 - val_acc: 0.0833\n",
      "Epoch 79/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4449 - acc: 0.4173 - val_loss: 6.9323 - val_acc: 0.0833\n",
      "Epoch 80/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4293 - acc: 0.4205 - val_loss: 6.9963 - val_acc: 0.0833\n",
      "Epoch 81/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.4271 - acc: 0.4211 - val_loss: 7.0244 - val_acc: 0.0833\n",
      "Epoch 82/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.4197 - acc: 0.4192 - val_loss: 7.1096 - val_acc: 0.0833\n",
      "Epoch 83/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4123 - acc: 0.4230 - val_loss: 7.3318 - val_acc: 0.0833\n",
      "Epoch 84/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4117 - acc: 0.4211 - val_loss: 6.9010 - val_acc: 0.0833\n",
      "Epoch 85/1000\n",
      "131/131 [==============================] - 2s 12ms/step - loss: 0.4046 - acc: 0.4211 - val_loss: 7.0989 - val_acc: 0.0833\n",
      "Epoch 86/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3942 - acc: 0.4224 - val_loss: 7.5325 - val_acc: 0.0833\n",
      "Epoch 87/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3914 - acc: 0.4237 - val_loss: 6.6762 - val_acc: 0.0833\n",
      "Epoch 88/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3890 - acc: 0.4230 - val_loss: 6.9591 - val_acc: 0.0833\n",
      "Epoch 89/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3784 - acc: 0.4256 - val_loss: 7.2892 - val_acc: 0.0833\n",
      "Epoch 90/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3744 - acc: 0.4243 - val_loss: 7.2082 - val_acc: 0.0833\n",
      "Epoch 91/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3700 - acc: 0.4262 - val_loss: 7.0120 - val_acc: 0.0833\n",
      "Epoch 92/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3618 - acc: 0.4256 - val_loss: 7.2994 - val_acc: 0.0833\n",
      "Epoch 93/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3529 - acc: 0.4262 - val_loss: 7.2923 - val_acc: 0.0833\n",
      "Epoch 94/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.3507 - acc: 0.4281 - val_loss: 6.9533 - val_acc: 0.0833\n",
      "Epoch 95/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.3491 - acc: 0.4256 - val_loss: 6.7040 - val_acc: 0.0833\n",
      "Epoch 96/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.3438 - acc: 0.4262 - val_loss: 6.9240 - val_acc: 0.0833\n",
      "Epoch 97/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3374 - acc: 0.4275 - val_loss: 7.1877 - val_acc: 0.0833\n",
      "Epoch 98/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3286 - acc: 0.4288 - val_loss: 7.2207 - val_acc: 0.0833\n",
      "Epoch 99/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3240 - acc: 0.4275 - val_loss: 6.8507 - val_acc: 0.0833\n",
      "Epoch 100/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.3185 - acc: 0.4281 - val_loss: 7.2851 - val_acc: 0.0833\n",
      "Epoch 101/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3156 - acc: 0.4288 - val_loss: 6.8588 - val_acc: 0.0833\n",
      "Epoch 102/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3091 - acc: 0.4307 - val_loss: 7.0765 - val_acc: 0.0833\n",
      "Epoch 103/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3044 - acc: 0.4294 - val_loss: 6.8629 - val_acc: 0.0833\n",
      "Epoch 104/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3004 - acc: 0.4307 - val_loss: 7.0383 - val_acc: 0.0833\n",
      "Epoch 105/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2956 - acc: 0.4319 - val_loss: 7.2429 - val_acc: 0.0833\n",
      "Epoch 106/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2873 - acc: 0.4313 - val_loss: 7.1243 - val_acc: 0.0833\n",
      "Epoch 107/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2867 - acc: 0.4307 - val_loss: 7.0631 - val_acc: 0.0833\n",
      "Epoch 108/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2869 - acc: 0.4313 - val_loss: 7.1929 - val_acc: 0.0833\n",
      "Epoch 109/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2774 - acc: 0.4313 - val_loss: 6.9922 - val_acc: 0.0833\n",
      "Epoch 110/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2716 - acc: 0.4326 - val_loss: 7.1848 - val_acc: 0.0833\n",
      "Epoch 111/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2673 - acc: 0.4300 - val_loss: 7.3254 - val_acc: 0.0833\n",
      "Epoch 112/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2641 - acc: 0.4313 - val_loss: 7.0875 - val_acc: 0.0833\n",
      "Epoch 113/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2581 - acc: 0.4345 - val_loss: 7.1500 - val_acc: 0.0833\n",
      "Epoch 114/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2592 - acc: 0.4319 - val_loss: 7.1191 - val_acc: 0.0833\n",
      "Epoch 115/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2500 - acc: 0.4351 - val_loss: 6.8551 - val_acc: 0.0833\n",
      "Epoch 116/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2519 - acc: 0.4332 - val_loss: 7.2381 - val_acc: 0.0833\n",
      "Epoch 117/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2414 - acc: 0.4338 - val_loss: 7.3621 - val_acc: 0.0833\n",
      "Epoch 118/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2358 - acc: 0.4351 - val_loss: 7.2515 - val_acc: 0.0833\n",
      "Epoch 119/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2326 - acc: 0.4358 - val_loss: 7.2923 - val_acc: 0.0833\n",
      "Epoch 120/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2307 - acc: 0.4345 - val_loss: 7.2816 - val_acc: 0.0556\n",
      "Epoch 121/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2292 - acc: 0.4351 - val_loss: 7.1662 - val_acc: 0.0833\n",
      "Epoch 122/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2230 - acc: 0.4370 - val_loss: 7.2569 - val_acc: 0.0833\n",
      "Epoch 123/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2175 - acc: 0.4351 - val_loss: 7.0957 - val_acc: 0.0833\n",
      "Epoch 124/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2127 - acc: 0.4370 - val_loss: 7.1106 - val_acc: 0.0833\n",
      "Epoch 125/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2100 - acc: 0.4364 - val_loss: 7.2906 - val_acc: 0.0833\n",
      "Epoch 126/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2071 - acc: 0.4364 - val_loss: 7.3006 - val_acc: 0.0833\n",
      "Epoch 127/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2084 - acc: 0.4345 - val_loss: 7.3210 - val_acc: 0.0833\n",
      "Epoch 128/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1998 - acc: 0.4377 - val_loss: 7.1433 - val_acc: 0.0833\n",
      "Epoch 129/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2000 - acc: 0.4377 - val_loss: 7.4247 - val_acc: 0.0833\n",
      "Epoch 130/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1929 - acc: 0.4351 - val_loss: 7.1801 - val_acc: 0.0833\n",
      "Epoch 131/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1900 - acc: 0.4370 - val_loss: 7.1752 - val_acc: 0.0833\n",
      "Epoch 132/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1863 - acc: 0.4377 - val_loss: 7.3926 - val_acc: 0.0833\n",
      "Epoch 133/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1851 - acc: 0.4370 - val_loss: 7.2911 - val_acc: 0.0833\n",
      "Epoch 134/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1812 - acc: 0.4389 - val_loss: 7.3860 - val_acc: 0.0833\n",
      "Epoch 135/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1771 - acc: 0.4396 - val_loss: 7.0818 - val_acc: 0.0833\n",
      "Epoch 136/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1729 - acc: 0.4396 - val_loss: 6.9502 - val_acc: 0.0833\n",
      "Epoch 137/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1752 - acc: 0.4389 - val_loss: 7.2806 - val_acc: 0.0833\n",
      "Epoch 138/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1681 - acc: 0.4396 - val_loss: 7.1737 - val_acc: 0.0833\n",
      "Epoch 139/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1669 - acc: 0.4396 - val_loss: 7.6134 - val_acc: 0.0833\n",
      "Epoch 140/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1627 - acc: 0.4402 - val_loss: 7.2540 - val_acc: 0.0833\n",
      "Epoch 141/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1594 - acc: 0.4396 - val_loss: 7.5668 - val_acc: 0.0556\n",
      "Epoch 142/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1557 - acc: 0.4402 - val_loss: 7.5260 - val_acc: 0.0833\n",
      "Epoch 143/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1537 - acc: 0.4402 - val_loss: 6.9714 - val_acc: 0.0833\n",
      "Epoch 144/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1566 - acc: 0.4377 - val_loss: 7.4942 - val_acc: 0.0833\n",
      "Epoch 145/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1492 - acc: 0.4402 - val_loss: 7.5163 - val_acc: 0.0833\n",
      "Epoch 146/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1478 - acc: 0.4389 - val_loss: 7.4829 - val_acc: 0.0833\n",
      "Epoch 147/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1429 - acc: 0.4396 - val_loss: 7.2852 - val_acc: 0.0833\n",
      "Epoch 148/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1389 - acc: 0.4408 - val_loss: 7.3968 - val_acc: 0.0833\n",
      "Epoch 149/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1389 - acc: 0.4389 - val_loss: 7.4616 - val_acc: 0.0833\n",
      "Epoch 150/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1359 - acc: 0.4408 - val_loss: 7.2686 - val_acc: 0.0833\n",
      "Epoch 151/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.4408 - val_loss: 7.1712 - val_acc: 0.0833\n",
      "Epoch 152/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1343 - acc: 0.4389 - val_loss: 7.5103 - val_acc: 0.0833\n",
      "Epoch 153/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1310 - acc: 0.4408 - val_loss: 7.4080 - val_acc: 0.0833\n",
      "Epoch 154/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.1268 - acc: 0.4396 - val_loss: 7.4086 - val_acc: 0.0833\n",
      "Epoch 155/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1247 - acc: 0.4402 - val_loss: 7.4728 - val_acc: 0.0833\n",
      "Epoch 156/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1218 - acc: 0.4402 - val_loss: 7.5620 - val_acc: 0.0833\n",
      "Epoch 157/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1185 - acc: 0.4415 - val_loss: 7.1786 - val_acc: 0.0833\n",
      "Epoch 158/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1183 - acc: 0.4408 - val_loss: 7.2823 - val_acc: 0.0833\n",
      "Epoch 159/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1157 - acc: 0.4415 - val_loss: 7.6901 - val_acc: 0.0556\n",
      "Epoch 160/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1137 - acc: 0.4396 - val_loss: 7.3263 - val_acc: 0.0833\n",
      "Epoch 161/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1099 - acc: 0.4415 - val_loss: 7.6499 - val_acc: 0.0833\n",
      "Epoch 162/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.1103 - acc: 0.4415 - val_loss: 7.5047 - val_acc: 0.0833\n",
      "Epoch 163/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1059 - acc: 0.4415 - val_loss: 7.4437 - val_acc: 0.0833\n",
      "Epoch 164/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1069 - acc: 0.4415 - val_loss: 7.4926 - val_acc: 0.0833\n",
      "Epoch 165/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.1034 - acc: 0.4408 - val_loss: 7.4832 - val_acc: 0.0833\n",
      "Epoch 166/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1028 - acc: 0.4408 - val_loss: 7.3203 - val_acc: 0.0833\n",
      "Epoch 167/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0996 - acc: 0.4402 - val_loss: 7.6723 - val_acc: 0.0556\n",
      "Epoch 168/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0984 - acc: 0.4415 - val_loss: 7.0800 - val_acc: 0.0833\n",
      "Epoch 169/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0987 - acc: 0.4402 - val_loss: 7.4404 - val_acc: 0.0833\n",
      "Epoch 170/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0939 - acc: 0.4415 - val_loss: 7.2717 - val_acc: 0.0833\n",
      "Epoch 171/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0936 - acc: 0.4408 - val_loss: 7.2265 - val_acc: 0.0833\n",
      "Epoch 172/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0895 - acc: 0.4408 - val_loss: 7.5104 - val_acc: 0.0833\n",
      "Epoch 173/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0893 - acc: 0.4415 - val_loss: 7.4080 - val_acc: 0.0833\n",
      "Epoch 174/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0879 - acc: 0.4408 - val_loss: 7.4665 - val_acc: 0.0833\n",
      "Epoch 175/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0870 - acc: 0.4415 - val_loss: 7.5163 - val_acc: 0.0833\n",
      "Epoch 176/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0843 - acc: 0.4415 - val_loss: 7.4959 - val_acc: 0.0556\n",
      "Epoch 177/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0820 - acc: 0.4421 - val_loss: 7.4862 - val_acc: 0.0833\n",
      "Epoch 178/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0815 - acc: 0.4427 - val_loss: 7.6637 - val_acc: 0.0556\n",
      "Epoch 179/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0791 - acc: 0.4421 - val_loss: 7.5399 - val_acc: 0.0833\n",
      "Epoch 180/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0770 - acc: 0.4427 - val_loss: 7.4265 - val_acc: 0.0833\n",
      "Epoch 181/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0759 - acc: 0.4421 - val_loss: 7.6667 - val_acc: 0.0556\n",
      "Epoch 182/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0759 - acc: 0.4421 - val_loss: 7.1896 - val_acc: 0.0833\n",
      "Epoch 183/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0745 - acc: 0.4427 - val_loss: 6.9627 - val_acc: 0.0833\n",
      "Epoch 184/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0739 - acc: 0.4421 - val_loss: 7.5504 - val_acc: 0.0833\n",
      "Epoch 185/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0697 - acc: 0.4427 - val_loss: 7.4965 - val_acc: 0.0833\n",
      "Epoch 186/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0693 - acc: 0.4427 - val_loss: 7.3280 - val_acc: 0.0833\n",
      "Epoch 187/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 0.0684 - acc: 0.4427 - val_loss: 7.7709 - val_acc: 0.0556\n",
      "Epoch 188/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0716 - acc: 0.4415 - val_loss: 7.4224 - val_acc: 0.0833\n",
      "Epoch 189/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0669 - acc: 0.4421 - val_loss: 7.3942 - val_acc: 0.0833\n",
      "Epoch 190/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0640 - acc: 0.4421 - val_loss: 7.5289 - val_acc: 0.0556\n",
      "Epoch 191/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0632 - acc: 0.4421 - val_loss: 7.4983 - val_acc: 0.0833\n",
      "Epoch 192/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0619 - acc: 0.4427 - val_loss: 7.5381 - val_acc: 0.0833\n",
      "Epoch 193/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0605 - acc: 0.4427 - val_loss: 7.4354 - val_acc: 0.0833\n",
      "Epoch 194/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0589 - acc: 0.4421 - val_loss: 7.2793 - val_acc: 0.0833\n",
      "Epoch 195/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0579 - acc: 0.4427 - val_loss: 7.6050 - val_acc: 0.0833\n",
      "Epoch 196/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0587 - acc: 0.4415 - val_loss: 7.3954 - val_acc: 0.0833\n",
      "Epoch 197/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0563 - acc: 0.4427 - val_loss: 7.5262 - val_acc: 0.0833\n",
      "Epoch 198/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0553 - acc: 0.4427 - val_loss: 7.5159 - val_acc: 0.0556\n",
      "Epoch 199/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0537 - acc: 0.4427 - val_loss: 7.3481 - val_acc: 0.0556\n",
      "Epoch 200/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0525 - acc: 0.4427 - val_loss: 7.4188 - val_acc: 0.0833\n",
      "Epoch 201/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0512 - acc: 0.4427 - val_loss: 7.2745 - val_acc: 0.0556\n",
      "Epoch 202/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0516 - acc: 0.4427 - val_loss: 7.7015 - val_acc: 0.0556\n",
      "Epoch 203/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 0.0537 - acc: 0.4421 - val_loss: 7.4426 - val_acc: 0.0278\n",
      "Epoch 204/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0530 - acc: 0.4427 - val_loss: 7.4204 - val_acc: 0.0278\n",
      "Epoch 205/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0473 - acc: 0.4427 - val_loss: 7.3655 - val_acc: 0.0556\n",
      "Epoch 206/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0459 - acc: 0.4427 - val_loss: 7.6599 - val_acc: 0.0278\n",
      "Epoch 207/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0456 - acc: 0.4427 - val_loss: 7.0573 - val_acc: 0.0556\n",
      "Epoch 208/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0458 - acc: 0.4427 - val_loss: 7.4622 - val_acc: 0.0833\n",
      "Epoch 209/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0442 - acc: 0.4427 - val_loss: 7.4810 - val_acc: 0.0556\n",
      "Epoch 210/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0439 - acc: 0.4427 - val_loss: 7.0877 - val_acc: 0.0556\n",
      "Epoch 211/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0424 - acc: 0.4427 - val_loss: 7.4706 - val_acc: 0.0556\n",
      "Epoch 212/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0420 - acc: 0.4427 - val_loss: 7.2041 - val_acc: 0.0556\n",
      "Epoch 213/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0405 - acc: 0.4427 - val_loss: 7.1069 - val_acc: 0.0278\n",
      "Epoch 214/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0408 - acc: 0.4427 - val_loss: 7.4085 - val_acc: 0.0556\n",
      "Epoch 215/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0395 - acc: 0.4427 - val_loss: 7.5193 - val_acc: 0.0833\n",
      "Epoch 216/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0395 - acc: 0.4427 - val_loss: 7.4845 - val_acc: 0.0833\n",
      "Epoch 217/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0382 - acc: 0.4427 - val_loss: 7.6719 - val_acc: 0.0278\n",
      "Epoch 218/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0388 - acc: 0.4427 - val_loss: 7.3427 - val_acc: 0.0278\n",
      "Epoch 219/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0371 - acc: 0.4427 - val_loss: 7.6508 - val_acc: 0.0556\n",
      "Epoch 220/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0361 - acc: 0.4427 - val_loss: 7.0030 - val_acc: 0.0556\n",
      "Epoch 221/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0345 - acc: 0.4427 - val_loss: 7.5692 - val_acc: 0.0278\n",
      "Epoch 222/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0338 - acc: 0.4427 - val_loss: 7.0786 - val_acc: 0.0556\n",
      "Epoch 223/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0334 - acc: 0.4427 - val_loss: 7.5868 - val_acc: 0.0278\n",
      "Epoch 224/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0329 - acc: 0.4427 - val_loss: 7.5047 - val_acc: 0.0556\n",
      "Epoch 225/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0327 - acc: 0.4427 - val_loss: 7.4082 - val_acc: 0.0556\n",
      "Epoch 226/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0324 - acc: 0.4427 - val_loss: 7.8173 - val_acc: 0.0278\n",
      "Epoch 227/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0310 - acc: 0.4427 - val_loss: 7.5738 - val_acc: 0.0556\n",
      "Epoch 228/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0309 - acc: 0.4427 - val_loss: 7.3820 - val_acc: 0.0556\n",
      "Epoch 229/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0306 - acc: 0.4427 - val_loss: 7.4217 - val_acc: 0.0278\n",
      "Epoch 230/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0289 - acc: 0.4427 - val_loss: 7.6862 - val_acc: 0.0833\n",
      "Epoch 231/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0294 - acc: 0.4421 - val_loss: 7.7438 - val_acc: 0.0278\n",
      "Epoch 232/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0276 - acc: 0.4427 - val_loss: 7.0992 - val_acc: 0.0556\n",
      "Epoch 233/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0279 - acc: 0.4427 - val_loss: 7.6685 - val_acc: 0.0556\n",
      "Epoch 234/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0277 - acc: 0.4427 - val_loss: 7.8478 - val_acc: 0.0278\n",
      "Epoch 235/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0264 - acc: 0.4427 - val_loss: 7.5194 - val_acc: 0.0556\n",
      "Epoch 236/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0256 - acc: 0.4427 - val_loss: 7.7266 - val_acc: 0.0278\n",
      "Epoch 237/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0256 - acc: 0.4427 - val_loss: 7.5274 - val_acc: 0.0556\n",
      "Epoch 238/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0246 - acc: 0.4427 - val_loss: 7.6773 - val_acc: 0.0278\n",
      "Epoch 239/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0249 - acc: 0.4427 - val_loss: 7.6942 - val_acc: 0.0278\n",
      "Epoch 240/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0247 - acc: 0.4427 - val_loss: 7.8240 - val_acc: 0.0278\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0236 - acc: 0.4427 - val_loss: 7.6813 - val_acc: 0.0278\n",
      "Epoch 242/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0228 - acc: 0.4427 - val_loss: 7.7813 - val_acc: 0.0278\n",
      "Epoch 243/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.0226 - acc: 0.4427 - val_loss: 7.0951 - val_acc: 0.0556\n",
      "Epoch 244/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0236 - acc: 0.4427 - val_loss: 7.9291 - val_acc: 0.0278\n",
      "Epoch 245/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0221 - acc: 0.4427 - val_loss: 7.8673 - val_acc: 0.0278\n",
      "Epoch 246/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0219 - acc: 0.4427 - val_loss: 7.7259 - val_acc: 0.0556\n",
      "Epoch 247/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0218 - acc: 0.4427 - val_loss: 7.5502 - val_acc: 0.0278\n",
      "Epoch 248/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0208 - acc: 0.4427 - val_loss: 7.5181 - val_acc: 0.0556\n",
      "Epoch 249/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0201 - acc: 0.4427 - val_loss: 7.8863 - val_acc: 0.0278\n",
      "Epoch 250/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0199 - acc: 0.4427 - val_loss: 7.3977 - val_acc: 0.0556\n",
      "Epoch 251/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0192 - acc: 0.4427 - val_loss: 7.9264 - val_acc: 0.0278\n",
      "Epoch 252/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0187 - acc: 0.4427 - val_loss: 7.5744 - val_acc: 0.0556\n",
      "Epoch 253/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0183 - acc: 0.4427 - val_loss: 7.7301 - val_acc: 0.0556\n",
      "Epoch 254/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 0.0180 - acc: 0.4427 - val_loss: 7.7385 - val_acc: 0.0556\n",
      "Epoch 255/1000\n",
      "131/131 [==============================] - 2s 16ms/step - loss: 0.0183 - acc: 0.4427 - val_loss: 7.3314 - val_acc: 0.0556\n",
      "Epoch 256/1000\n",
      "131/131 [==============================] - 2s 19ms/step - loss: 0.0183 - acc: 0.4427 - val_loss: 7.7554 - val_acc: 0.0556\n",
      "Epoch 257/1000\n",
      "131/131 [==============================] - 2s 18ms/step - loss: 0.0170 - acc: 0.4427 - val_loss: 7.8529 - val_acc: 0.0278\n",
      "Epoch 258/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0170 - acc: 0.4427 - val_loss: 7.7682 - val_acc: 0.0278\n",
      "Epoch 259/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0164 - acc: 0.4427 - val_loss: 7.8207 - val_acc: 0.0556\n",
      "Epoch 260/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0163 - acc: 0.4427 - val_loss: 7.7790 - val_acc: 0.0556\n",
      "Epoch 261/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0162 - acc: 0.4427 - val_loss: 7.9087 - val_acc: 0.0278\n",
      "Epoch 262/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0164 - acc: 0.4427 - val_loss: 7.6438 - val_acc: 0.0556\n",
      "Epoch 263/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0159 - acc: 0.4427 - val_loss: 7.7850 - val_acc: 0.0556\n",
      "Epoch 264/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0149 - acc: 0.4427 - val_loss: 7.9563 - val_acc: 0.0278\n",
      "Epoch 265/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0147 - acc: 0.4427 - val_loss: 7.7777 - val_acc: 0.0556\n",
      "Epoch 266/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0140 - acc: 0.4427 - val_loss: 7.9144 - val_acc: 0.0278\n",
      "Epoch 267/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0136 - acc: 0.4427 - val_loss: 7.9328 - val_acc: 0.0278\n",
      "Epoch 268/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0136 - acc: 0.4427 - val_loss: 7.6473 - val_acc: 0.0556\n",
      "Epoch 269/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0141 - acc: 0.4427 - val_loss: 7.5304 - val_acc: 0.0278\n",
      "Epoch 270/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0140 - acc: 0.4427 - val_loss: 7.7270 - val_acc: 0.0278\n",
      "Epoch 271/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0135 - acc: 0.4427 - val_loss: 7.7571 - val_acc: 0.0556\n",
      "Epoch 272/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0131 - acc: 0.4427 - val_loss: 7.4662 - val_acc: 0.0278\n",
      "Epoch 273/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0127 - acc: 0.4427 - val_loss: 7.7471 - val_acc: 0.0556\n",
      "Epoch 274/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0119 - acc: 0.4427 - val_loss: 7.6656 - val_acc: 0.0556\n",
      "Epoch 275/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0115 - acc: 0.4427 - val_loss: 7.6268 - val_acc: 0.0556\n",
      "Epoch 276/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0118 - acc: 0.4427 - val_loss: 7.8887 - val_acc: 0.0278\n",
      "Epoch 277/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 0.0117 - acc: 0.4427 - val_loss: 7.7690 - val_acc: 0.0556\n",
      "Epoch 278/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0113 - acc: 0.4427 - val_loss: 7.8620 - val_acc: 0.0278\n",
      "Epoch 279/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0108 - acc: 0.4427 - val_loss: 7.7733 - val_acc: 0.0278\n",
      "Epoch 280/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0108 - acc: 0.4427 - val_loss: 7.9966 - val_acc: 0.0278\n",
      "Epoch 281/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0111 - acc: 0.4427 - val_loss: 7.9775 - val_acc: 0.0278\n",
      "Epoch 282/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0112 - acc: 0.4427 - val_loss: 7.7343 - val_acc: 0.0556\n",
      "Epoch 283/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0102 - acc: 0.4427 - val_loss: 7.7811 - val_acc: 0.0556\n",
      "Epoch 284/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0103 - acc: 0.4421 - val_loss: 7.7962 - val_acc: 0.0278\n",
      "Epoch 285/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0099 - acc: 0.4427 - val_loss: 7.9815 - val_acc: 0.0278\n",
      "Epoch 286/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0095 - acc: 0.4427 - val_loss: 7.7920 - val_acc: 0.0556\n",
      "Epoch 287/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0092 - acc: 0.4427 - val_loss: 7.9315 - val_acc: 0.0278\n",
      "Epoch 288/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0092 - acc: 0.4427 - val_loss: 7.9318 - val_acc: 0.0278\n",
      "Epoch 289/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0095 - acc: 0.4427 - val_loss: 7.9433 - val_acc: 0.0278\n",
      "Epoch 290/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0090 - acc: 0.4427 - val_loss: 8.0236 - val_acc: 0.0278\n",
      "Epoch 291/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0093 - acc: 0.4427 - val_loss: 8.0268 - val_acc: 0.0278\n",
      "Epoch 292/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0084 - acc: 0.4427 - val_loss: 7.9114 - val_acc: 0.0278\n",
      "Epoch 293/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0084 - acc: 0.4427 - val_loss: 7.9194 - val_acc: 0.0278\n",
      "Epoch 294/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0080 - acc: 0.4427 - val_loss: 7.9626 - val_acc: 0.0278\n",
      "Epoch 295/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0078 - acc: 0.4427 - val_loss: 7.9803 - val_acc: 0.0278\n",
      "Epoch 296/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0077 - acc: 0.4427 - val_loss: 8.0228 - val_acc: 0.0278\n",
      "Epoch 297/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0076 - acc: 0.4427 - val_loss: 8.0956 - val_acc: 0.0278\n",
      "Epoch 298/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0078 - acc: 0.4427 - val_loss: 8.0293 - val_acc: 0.0278\n",
      "Epoch 299/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0074 - acc: 0.4427 - val_loss: 7.9963 - val_acc: 0.0278\n",
      "Epoch 300/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0071 - acc: 0.4427 - val_loss: 7.9334 - val_acc: 0.0278\n",
      "Epoch 301/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0072 - acc: 0.4427 - val_loss: 8.0461 - val_acc: 0.0278\n",
      "Epoch 302/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0071 - acc: 0.4427 - val_loss: 8.0434 - val_acc: 0.0278\n",
      "Epoch 303/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0068 - acc: 0.4427 - val_loss: 7.9394 - val_acc: 0.0556\n",
      "Epoch 304/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0066 - acc: 0.4427 - val_loss: 7.9728 - val_acc: 0.0278\n",
      "Epoch 305/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0064 - acc: 0.4427 - val_loss: 7.9385 - val_acc: 0.0278\n",
      "Epoch 306/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0064 - acc: 0.4427 - val_loss: 8.1520 - val_acc: 0.0278\n",
      "Epoch 307/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0065 - acc: 0.4427 - val_loss: 8.0897 - val_acc: 0.0278\n",
      "Epoch 308/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0061 - acc: 0.4427 - val_loss: 7.9137 - val_acc: 0.0278\n",
      "Epoch 309/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0062 - acc: 0.4427 - val_loss: 8.1504 - val_acc: 0.0278\n",
      "Epoch 310/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0061 - acc: 0.4427 - val_loss: 8.0235 - val_acc: 0.0278\n",
      "Epoch 311/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0058 - acc: 0.4427 - val_loss: 8.0677 - val_acc: 0.0278\n",
      "Epoch 312/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0056 - acc: 0.4427 - val_loss: 8.1624 - val_acc: 0.0278\n",
      "Epoch 313/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0059 - acc: 0.4427 - val_loss: 8.0754 - val_acc: 0.0278\n",
      "Epoch 314/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0055 - acc: 0.4427 - val_loss: 8.2172 - val_acc: 0.0278\n",
      "Epoch 315/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0052 - acc: 0.4427 - val_loss: 8.0742 - val_acc: 0.0278\n",
      "Epoch 316/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0055 - acc: 0.4427 - val_loss: 8.0298 - val_acc: 0.0278\n",
      "Epoch 317/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0051 - acc: 0.4427 - val_loss: 8.1388 - val_acc: 0.0278\n",
      "Epoch 318/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0050 - acc: 0.4427 - val_loss: 8.1077 - val_acc: 0.0278\n",
      "Epoch 319/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0049 - acc: 0.4427 - val_loss: 8.0200 - val_acc: 0.0278\n",
      "Epoch 320/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0048 - acc: 0.4427 - val_loss: 8.1828 - val_acc: 0.0278\n",
      "Epoch 321/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0047 - acc: 0.4427 - val_loss: 8.2558 - val_acc: 0.0278\n",
      "Epoch 322/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0047 - acc: 0.4427 - val_loss: 8.1817 - val_acc: 0.0278\n",
      "Epoch 323/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0045 - acc: 0.4427 - val_loss: 8.1815 - val_acc: 0.0278\n",
      "Epoch 324/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 0.4427 - val_loss: 8.1928 - val_acc: 0.0278\n",
      "Epoch 325/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0044 - acc: 0.4427 - val_loss: 8.1841 - val_acc: 0.0278\n",
      "Epoch 326/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0058 - acc: 0.4421 - val_loss: 8.0584 - val_acc: 0.0556\n",
      "Epoch 327/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0041 - acc: 0.4427 - val_loss: 8.0874 - val_acc: 0.0278\n",
      "Epoch 328/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0040 - acc: 0.4427 - val_loss: 8.0940 - val_acc: 0.0278\n",
      "Epoch 329/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0038 - acc: 0.4427 - val_loss: 8.1271 - val_acc: 0.0278\n",
      "Epoch 330/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0037 - acc: 0.4427 - val_loss: 8.1536 - val_acc: 0.0278\n",
      "Epoch 331/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0038 - acc: 0.4427 - val_loss: 8.2281 - val_acc: 0.0278\n",
      "Epoch 332/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0038 - acc: 0.4427 - val_loss: 8.2705 - val_acc: 0.0278\n",
      "Epoch 333/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0041 - acc: 0.4427 - val_loss: 8.3107 - val_acc: 0.0278\n",
      "Epoch 334/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0038 - acc: 0.4427 - val_loss: 8.2260 - val_acc: 0.0278\n",
      "Epoch 335/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0036 - acc: 0.4427 - val_loss: 8.3229 - val_acc: 0.0278\n",
      "Epoch 336/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0035 - acc: 0.4427 - val_loss: 8.2113 - val_acc: 0.0278\n",
      "Epoch 337/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0034 - acc: 0.4427 - val_loss: 8.1359 - val_acc: 0.0278\n",
      "Epoch 338/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0033 - acc: 0.4427 - val_loss: 8.1834 - val_acc: 0.0278\n",
      "Epoch 339/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0032 - acc: 0.4427 - val_loss: 8.1961 - val_acc: 0.0278\n",
      "Epoch 340/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0031 - acc: 0.4427 - val_loss: 8.1866 - val_acc: 0.0278\n",
      "Epoch 341/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0030 - acc: 0.4427 - val_loss: 8.1829 - val_acc: 0.0278\n",
      "Epoch 342/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0032 - acc: 0.4427 - val_loss: 8.1664 - val_acc: 0.0278\n",
      "Epoch 343/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0031 - acc: 0.4427 - val_loss: 8.1807 - val_acc: 0.0278\n",
      "Epoch 344/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0031 - acc: 0.4427 - val_loss: 8.1787 - val_acc: 0.0278\n",
      "Epoch 345/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0029 - acc: 0.4427 - val_loss: 8.2084 - val_acc: 0.0278\n",
      "Epoch 346/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0028 - acc: 0.4427 - val_loss: 8.2362 - val_acc: 0.0278\n",
      "Epoch 347/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 0.4427 - val_loss: 8.2614 - val_acc: 0.0278\n",
      "Epoch 348/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0027 - acc: 0.4427 - val_loss: 8.2329 - val_acc: 0.0278\n",
      "Epoch 349/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0027 - acc: 0.4427 - val_loss: 8.1163 - val_acc: 0.0278\n",
      "Epoch 350/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0026 - acc: 0.4427 - val_loss: 8.3056 - val_acc: 0.0278\n",
      "Epoch 351/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 0.4427 - val_loss: 8.2449 - val_acc: 0.0278\n",
      "Epoch 352/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0027 - acc: 0.4427 - val_loss: 8.2385 - val_acc: 0.0278\n",
      "Epoch 353/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 0.4427 - val_loss: 8.2905 - val_acc: 0.0556\n",
      "Epoch 354/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0027 - acc: 0.4427 - val_loss: 8.2337 - val_acc: 0.0556\n",
      "Epoch 355/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0026 - acc: 0.4427 - val_loss: 8.0723 - val_acc: 0.0278\n",
      "Epoch 356/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0026 - acc: 0.4427 - val_loss: 8.2219 - val_acc: 0.0278\n",
      "Epoch 357/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 0.0024 - acc: 0.4427 - val_loss: 8.2417 - val_acc: 0.0278\n",
      "Epoch 358/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 0.4427 - val_loss: 8.2641 - val_acc: 0.0278\n",
      "Epoch 359/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.4427 - val_loss: 8.2718 - val_acc: 0.0278\n",
      "Epoch 360/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0021 - acc: 0.4427 - val_loss: 8.2363 - val_acc: 0.0278\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.2625 - val_acc: 0.0278\n",
      "Epoch 362/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.3199 - val_acc: 0.0278\n",
      "Epoch 363/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.0996 - val_acc: 0.0278\n",
      "Epoch 364/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.4107 - val_acc: 0.0556\n",
      "Epoch 365/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.2946 - val_acc: 0.0278\n",
      "Epoch 366/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.4427 - val_loss: 8.3233 - val_acc: 0.0278\n",
      "Epoch 367/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.4427 - val_loss: 8.2914 - val_acc: 0.0278\n",
      "Epoch 368/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 0.4427 - val_loss: 8.2604 - val_acc: 0.0278\n",
      "Epoch 369/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0018 - acc: 0.4427 - val_loss: 8.2425 - val_acc: 0.0556\n",
      "Epoch 370/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 0.4427 - val_loss: 8.1238 - val_acc: 0.0556\n",
      "Epoch 371/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0022 - acc: 0.4427 - val_loss: 8.3560 - val_acc: 0.0556\n",
      "Epoch 372/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.4427 - val_loss: 8.3534 - val_acc: 0.0278\n",
      "Epoch 373/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 0.0016 - acc: 0.4427 - val_loss: 8.2657 - val_acc: 0.0278\n",
      "Epoch 374/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 0.4427 - val_loss: 8.3094 - val_acc: 0.0278\n",
      "Epoch 375/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.3234 - val_acc: 0.0278\n",
      "Epoch 376/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.3122 - val_acc: 0.0278\n",
      "Epoch 377/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.3810 - val_acc: 0.0278\n",
      "Epoch 378/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.3780 - val_acc: 0.0278\n",
      "Epoch 379/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.3934 - val_acc: 0.0278\n",
      "Epoch 380/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 0.4427 - val_loss: 8.3411 - val_acc: 0.0278\n",
      "Epoch 381/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0015 - acc: 0.4427 - val_loss: 8.4135 - val_acc: 0.0278\n",
      "Epoch 382/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.4427 - val_loss: 8.3092 - val_acc: 0.0278\n",
      "Epoch 383/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0014 - acc: 0.4427 - val_loss: 8.3309 - val_acc: 0.0278\n",
      "Epoch 384/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0013 - acc: 0.4427 - val_loss: 8.3391 - val_acc: 0.0278\n",
      "Epoch 385/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 0.4427 - val_loss: 8.4084 - val_acc: 0.0278\n",
      "Epoch 386/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 0.4427 - val_loss: 8.2972 - val_acc: 0.0556\n",
      "Epoch 387/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 0.4427 - val_loss: 8.3773 - val_acc: 0.0278\n",
      "Epoch 388/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0014 - acc: 0.4427 - val_loss: 8.3169 - val_acc: 0.0278\n",
      "Epoch 389/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 0.4427 - val_loss: 8.3958 - val_acc: 0.0278\n",
      "Epoch 390/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0011 - acc: 0.4427 - val_loss: 8.3442 - val_acc: 0.0278\n",
      "Epoch 391/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.0012 - acc: 0.4427 - val_loss: 8.3690 - val_acc: 0.0278\n",
      "Epoch 392/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0011 - acc: 0.4427 - val_loss: 8.3795 - val_acc: 0.0278\n",
      "Epoch 393/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0011 - acc: 0.4427 - val_loss: 8.3565 - val_acc: 0.0278\n",
      "Epoch 394/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0010 - acc: 0.4427 - val_loss: 8.4380 - val_acc: 0.0556\n",
      "Epoch 395/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0010 - acc: 0.4427 - val_loss: 8.3676 - val_acc: 0.0278\n",
      "Epoch 396/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.0011 - acc: 0.4427 - val_loss: 8.3546 - val_acc: 0.0278\n",
      "Epoch 397/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.0011 - acc: 0.4427 - val_loss: 8.4588 - val_acc: 0.0278\n",
      "Epoch 398/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 9.8995e-04 - acc: 0.4427 - val_loss: 8.3644 - val_acc: 0.0278\n",
      "Epoch 399/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.3705e-04 - acc: 0.4427 - val_loss: 8.3847 - val_acc: 0.0556\n",
      "Epoch 400/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.3403e-04 - acc: 0.4427 - val_loss: 8.3700 - val_acc: 0.0278\n",
      "Epoch 401/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0010 - acc: 0.4427 - val_loss: 8.3495 - val_acc: 0.0278\n",
      "Epoch 402/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0012 - acc: 0.4427 - val_loss: 8.3903 - val_acc: 0.0278\n",
      "Epoch 403/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 8.7916e-04 - acc: 0.4427 - val_loss: 8.4685 - val_acc: 0.0278\n",
      "Epoch 404/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.7266e-04 - acc: 0.4427 - val_loss: 8.3576 - val_acc: 0.0278\n",
      "Epoch 405/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 8.2150e-04 - acc: 0.4427 - val_loss: 8.4100 - val_acc: 0.0278\n",
      "Epoch 406/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.6685e-04 - acc: 0.4427 - val_loss: 8.3538 - val_acc: 0.0278\n",
      "Epoch 407/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 8.1651e-04 - acc: 0.4427 - val_loss: 8.3344 - val_acc: 0.0278\n",
      "Epoch 408/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.9972e-04 - acc: 0.4427 - val_loss: 8.3365 - val_acc: 0.0278\n",
      "Epoch 409/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.7914e-04 - acc: 0.4427 - val_loss: 8.4655 - val_acc: 0.0278\n",
      "Epoch 410/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.5208e-04 - acc: 0.4427 - val_loss: 8.4081 - val_acc: 0.0278\n",
      "Epoch 411/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.4854e-04 - acc: 0.4427 - val_loss: 8.4420 - val_acc: 0.0278\n",
      "Epoch 412/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.2333e-04 - acc: 0.4427 - val_loss: 8.3915 - val_acc: 0.0278\n",
      "Epoch 413/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 8.6363e-04 - acc: 0.4427 - val_loss: 8.4382 - val_acc: 0.0278\n",
      "Epoch 414/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.6241e-04 - acc: 0.4427 - val_loss: 8.3065 - val_acc: 0.0556\n",
      "Epoch 415/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.0010 - acc: 0.4427 - val_loss: 8.4785 - val_acc: 0.0556\n",
      "Epoch 416/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.6350e-04 - acc: 0.4427 - val_loss: 8.4297 - val_acc: 0.0278\n",
      "Epoch 417/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.8216e-04 - acc: 0.4427 - val_loss: 8.3970 - val_acc: 0.0278\n",
      "Epoch 418/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.4489e-04 - acc: 0.4427 - val_loss: 8.4648 - val_acc: 0.0278\n",
      "Epoch 419/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.2574e-04 - acc: 0.4427 - val_loss: 8.3942 - val_acc: 0.0278\n",
      "Epoch 420/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.3146e-04 - acc: 0.4427 - val_loss: 8.4252 - val_acc: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0569e-04 - acc: 0.4427 - val_loss: 8.4760 - val_acc: 0.0556\n",
      "Epoch 422/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0514e-04 - acc: 0.4427 - val_loss: 8.4482 - val_acc: 0.0278\n",
      "Epoch 423/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 6.1571e-04 - acc: 0.4427 - val_loss: 8.4767 - val_acc: 0.0556\n",
      "Epoch 424/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.1578e-04 - acc: 0.4427 - val_loss: 8.4846 - val_acc: 0.0278\n",
      "Epoch 425/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.7533e-04 - acc: 0.4427 - val_loss: 8.5754 - val_acc: 0.0278\n",
      "Epoch 426/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 6.4992e-04 - acc: 0.4427 - val_loss: 8.4857 - val_acc: 0.0278\n",
      "Epoch 427/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.6492e-04 - acc: 0.4427 - val_loss: 8.3675 - val_acc: 0.0278\n",
      "Epoch 428/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.6157e-04 - acc: 0.4427 - val_loss: 8.4183 - val_acc: 0.0278\n",
      "Epoch 429/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 5.5325e-04 - acc: 0.4427 - val_loss: 8.4189 - val_acc: 0.0278\n",
      "Epoch 430/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.3021e-04 - acc: 0.4427 - val_loss: 8.4792 - val_acc: 0.0278\n",
      "Epoch 431/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 5.1032e-04 - acc: 0.4427 - val_loss: 8.5065 - val_acc: 0.0556\n",
      "Epoch 432/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 5.0498e-04 - acc: 0.4427 - val_loss: 8.4505 - val_acc: 0.0278\n",
      "Epoch 433/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.4761e-04 - acc: 0.4427 - val_loss: 8.4351 - val_acc: 0.0278\n",
      "Epoch 434/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.9886e-04 - acc: 0.4427 - val_loss: 8.5805 - val_acc: 0.0556\n",
      "Epoch 435/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.7949e-04 - acc: 0.4427 - val_loss: 8.5401 - val_acc: 0.0278\n",
      "Epoch 436/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.5728e-04 - acc: 0.4427 - val_loss: 8.4279 - val_acc: 0.0278\n",
      "Epoch 437/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.4889e-04 - acc: 0.4427 - val_loss: 8.5300 - val_acc: 0.0278\n",
      "Epoch 438/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.4828e-04 - acc: 0.4427 - val_loss: 8.4521 - val_acc: 0.0278\n",
      "Epoch 439/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.5358e-04 - acc: 0.4427 - val_loss: 8.4334 - val_acc: 0.0278\n",
      "Epoch 440/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.5369e-04 - acc: 0.4427 - val_loss: 8.4983 - val_acc: 0.0556\n",
      "Epoch 441/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.3252e-04 - acc: 0.4427 - val_loss: 8.5134 - val_acc: 0.0278\n",
      "Epoch 442/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.2752e-04 - acc: 0.4427 - val_loss: 8.4034 - val_acc: 0.0278\n",
      "Epoch 443/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.1446e-04 - acc: 0.4427 - val_loss: 8.5279 - val_acc: 0.0278\n",
      "Epoch 444/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.9347e-04 - acc: 0.4427 - val_loss: 8.5063 - val_acc: 0.0278\n",
      "Epoch 445/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.8310e-04 - acc: 0.4427 - val_loss: 8.5293 - val_acc: 0.0278\n",
      "Epoch 446/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.9384e-04 - acc: 0.4427 - val_loss: 8.5459 - val_acc: 0.0556\n",
      "Epoch 447/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.8911e-04 - acc: 0.4427 - val_loss: 8.4951 - val_acc: 0.0278\n",
      "Epoch 448/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.7446e-04 - acc: 0.4427 - val_loss: 8.4674 - val_acc: 0.0278\n",
      "Epoch 449/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.5954e-04 - acc: 0.4427 - val_loss: 8.4829 - val_acc: 0.0278\n",
      "Epoch 450/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6278e-04 - acc: 0.4427 - val_loss: 8.4922 - val_acc: 0.0278\n",
      "Epoch 451/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6924e-04 - acc: 0.4427 - val_loss: 8.4886 - val_acc: 0.0278\n",
      "Epoch 452/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.3949e-04 - acc: 0.4427 - val_loss: 8.5204 - val_acc: 0.0278\n",
      "Epoch 453/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.2949e-04 - acc: 0.4427 - val_loss: 8.5455 - val_acc: 0.0278\n",
      "Epoch 454/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.3114e-04 - acc: 0.4427 - val_loss: 8.5323 - val_acc: 0.0556\n",
      "Epoch 455/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.3049e-04 - acc: 0.4427 - val_loss: 8.5199 - val_acc: 0.0278\n",
      "Epoch 456/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.2048e-04 - acc: 0.4427 - val_loss: 8.5289 - val_acc: 0.0278\n",
      "Epoch 457/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.2157e-04 - acc: 0.4427 - val_loss: 8.4170 - val_acc: 0.0278\n",
      "Epoch 458/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.5053e-04 - acc: 0.4427 - val_loss: 8.5490 - val_acc: 0.0278\n",
      "Epoch 459/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1490e-04 - acc: 0.4427 - val_loss: 8.6003 - val_acc: 0.0278\n",
      "Epoch 460/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.9746e-04 - acc: 0.4427 - val_loss: 8.5060 - val_acc: 0.0278\n",
      "Epoch 461/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.8791e-04 - acc: 0.4427 - val_loss: 8.4288 - val_acc: 0.0556\n",
      "Epoch 462/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9253e-04 - acc: 0.4427 - val_loss: 8.5631 - val_acc: 0.0278\n",
      "Epoch 463/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7725e-04 - acc: 0.4427 - val_loss: 8.5545 - val_acc: 0.0278\n",
      "Epoch 464/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.8848e-04 - acc: 0.4427 - val_loss: 8.5989 - val_acc: 0.0278\n",
      "Epoch 465/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.6914e-04 - acc: 0.4427 - val_loss: 8.5797 - val_acc: 0.0278\n",
      "Epoch 466/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6359e-04 - acc: 0.4427 - val_loss: 8.6018 - val_acc: 0.0278\n",
      "Epoch 467/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6089e-04 - acc: 0.4427 - val_loss: 8.4972 - val_acc: 0.0278\n",
      "Epoch 468/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.6133e-04 - acc: 0.4427 - val_loss: 8.4909 - val_acc: 0.0278\n",
      "Epoch 469/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4653e-04 - acc: 0.4427 - val_loss: 8.6187 - val_acc: 0.0278\n",
      "Epoch 470/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.4917e-04 - acc: 0.4427 - val_loss: 8.5241 - val_acc: 0.0278\n",
      "Epoch 471/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.4809e-04 - acc: 0.4427 - val_loss: 8.5566 - val_acc: 0.0278\n",
      "Epoch 472/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.4053e-04 - acc: 0.4427 - val_loss: 8.5697 - val_acc: 0.0278\n",
      "Epoch 473/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3222e-04 - acc: 0.4427 - val_loss: 8.4919 - val_acc: 0.0278\n",
      "Epoch 474/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3808e-04 - acc: 0.4427 - val_loss: 8.5161 - val_acc: 0.0278\n",
      "Epoch 475/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4872e-04 - acc: 0.4427 - val_loss: 8.5521 - val_acc: 0.0278\n",
      "Epoch 476/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.2751e-04 - acc: 0.4427 - val_loss: 8.5758 - val_acc: 0.0278\n",
      "Epoch 477/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.0891e-04 - acc: 0.4427 - val_loss: 8.5230 - val_acc: 0.0278\n",
      "Epoch 478/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.3102e-04 - acc: 0.4427 - val_loss: 8.3595 - val_acc: 0.0278\n",
      "Epoch 479/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1285e-04 - acc: 0.4427 - val_loss: 8.3835 - val_acc: 0.0278\n",
      "Epoch 480/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.0463e-04 - acc: 0.4427 - val_loss: 8.3841 - val_acc: 0.0278\n",
      "Epoch 481/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.9519e-04 - acc: 0.4427 - val_loss: 8.3882 - val_acc: 0.0278\n",
      "Epoch 482/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.9106e-04 - acc: 0.4427 - val_loss: 8.3542 - val_acc: 0.0278\n",
      "Epoch 483/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 1.9165e-04 - acc: 0.4427 - val_loss: 8.4174 - val_acc: 0.0278\n",
      "Epoch 484/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 1.9197e-04 - acc: 0.4427 - val_loss: 8.4526 - val_acc: 0.0278\n",
      "Epoch 485/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.9012e-04 - acc: 0.4427 - val_loss: 8.5132 - val_acc: 0.0278\n",
      "Epoch 486/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.7968e-04 - acc: 0.4427 - val_loss: 8.4423 - val_acc: 0.0278\n",
      "Epoch 487/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.7828e-04 - acc: 0.4427 - val_loss: 8.4919 - val_acc: 0.0278\n",
      "Epoch 488/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.8380e-04 - acc: 0.4427 - val_loss: 8.4813 - val_acc: 0.0278\n",
      "Epoch 489/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.7793e-04 - acc: 0.4427 - val_loss: 8.4917 - val_acc: 0.0278\n",
      "Epoch 490/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.7068e-04 - acc: 0.4427 - val_loss: 8.6305 - val_acc: 0.0278\n",
      "Epoch 491/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.7490e-04 - acc: 0.4427 - val_loss: 8.4233 - val_acc: 0.0278\n",
      "Epoch 492/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.7064e-04 - acc: 0.4427 - val_loss: 8.5669 - val_acc: 0.0278\n",
      "Epoch 493/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.5888e-04 - acc: 0.4427 - val_loss: 8.5418 - val_acc: 0.0278\n",
      "Epoch 494/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5388e-04 - acc: 0.4427 - val_loss: 8.5357 - val_acc: 0.0278\n",
      "Epoch 495/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5269e-04 - acc: 0.4427 - val_loss: 8.4567 - val_acc: 0.0278\n",
      "Epoch 496/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5398e-04 - acc: 0.4427 - val_loss: 8.5397 - val_acc: 0.0278\n",
      "Epoch 497/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5267e-04 - acc: 0.4427 - val_loss: 8.5355 - val_acc: 0.0278\n",
      "Epoch 498/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5614e-04 - acc: 0.4427 - val_loss: 8.4967 - val_acc: 0.0278\n",
      "Epoch 499/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4596e-04 - acc: 0.4427 - val_loss: 8.6216 - val_acc: 0.0278\n",
      "Epoch 500/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4605e-04 - acc: 0.4427 - val_loss: 8.5083 - val_acc: 0.0278\n",
      "Epoch 501/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4607e-04 - acc: 0.4427 - val_loss: 8.5672 - val_acc: 0.0278\n",
      "Epoch 502/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3672e-04 - acc: 0.4427 - val_loss: 8.5299 - val_acc: 0.0278\n",
      "Epoch 503/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4815e-04 - acc: 0.4427 - val_loss: 8.5973 - val_acc: 0.0278\n",
      "Epoch 504/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.3102e-04 - acc: 0.4427 - val_loss: 8.5728 - val_acc: 0.0278\n",
      "Epoch 505/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2718e-04 - acc: 0.4427 - val_loss: 8.5379 - val_acc: 0.0278\n",
      "Epoch 506/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2347e-04 - acc: 0.4427 - val_loss: 8.5844 - val_acc: 0.0278\n",
      "Epoch 507/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2269e-04 - acc: 0.4427 - val_loss: 8.6013 - val_acc: 0.0278\n",
      "Epoch 508/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.2048e-04 - acc: 0.4427 - val_loss: 8.5103 - val_acc: 0.0278\n",
      "Epoch 509/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2460e-04 - acc: 0.4427 - val_loss: 8.4114 - val_acc: 0.0278\n",
      "Epoch 510/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.2581e-04 - acc: 0.4427 - val_loss: 8.4962 - val_acc: 0.0278\n",
      "Epoch 511/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1751e-04 - acc: 0.4427 - val_loss: 8.5372 - val_acc: 0.0278\n",
      "Epoch 512/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1413e-04 - acc: 0.4427 - val_loss: 8.5359 - val_acc: 0.0278\n",
      "Epoch 513/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0989e-04 - acc: 0.4427 - val_loss: 8.6306 - val_acc: 0.0556\n",
      "Epoch 514/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0692e-04 - acc: 0.4427 - val_loss: 8.5149 - val_acc: 0.0278\n",
      "Epoch 515/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.1042e-04 - acc: 0.4427 - val_loss: 8.6296 - val_acc: 0.0278\n",
      "Epoch 516/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 1.0504e-04 - acc: 0.4427 - val_loss: 8.5855 - val_acc: 0.0278\n",
      "Epoch 517/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0330e-04 - acc: 0.4427 - val_loss: 8.7060 - val_acc: 0.0556\n",
      "Epoch 518/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3091e-04 - acc: 0.4427 - val_loss: 8.5514 - val_acc: 0.0278\n",
      "Epoch 519/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2212e-04 - acc: 0.4427 - val_loss: 8.5405 - val_acc: 0.0278\n",
      "Epoch 520/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.0153e-04 - acc: 0.4427 - val_loss: 8.5909 - val_acc: 0.0278\n",
      "Epoch 521/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.4378e-05 - acc: 0.4427 - val_loss: 8.6437 - val_acc: 0.0278\n",
      "Epoch 522/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 9.2002e-05 - acc: 0.4427 - val_loss: 8.5954 - val_acc: 0.0278\n",
      "Epoch 523/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 9.0906e-05 - acc: 0.4427 - val_loss: 8.6219 - val_acc: 0.0278\n",
      "Epoch 524/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 8.9237e-05 - acc: 0.4427 - val_loss: 8.6263 - val_acc: 0.0278\n",
      "Epoch 525/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.0029e-05 - acc: 0.4427 - val_loss: 8.6328 - val_acc: 0.0278\n",
      "Epoch 526/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 8.7678e-05 - acc: 0.4427 - val_loss: 8.6216 - val_acc: 0.0278\n",
      "Epoch 527/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 8.6564e-05 - acc: 0.4427 - val_loss: 8.6516 - val_acc: 0.0278\n",
      "Epoch 528/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.8072e-05 - acc: 0.4427 - val_loss: 8.6638 - val_acc: 0.0278\n",
      "Epoch 529/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.1764e-05 - acc: 0.4427 - val_loss: 8.7004 - val_acc: 0.0278\n",
      "Epoch 530/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 8.1251e-05 - acc: 0.4427 - val_loss: 8.6672 - val_acc: 0.0278\n",
      "Epoch 531/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.8937e-05 - acc: 0.4427 - val_loss: 8.6511 - val_acc: 0.0278\n",
      "Epoch 532/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 7.9309e-05 - acc: 0.4427 - val_loss: 8.7063 - val_acc: 0.0278\n",
      "Epoch 533/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.7386e-05 - acc: 0.4427 - val_loss: 8.6971 - val_acc: 0.0278\n",
      "Epoch 534/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.5770e-05 - acc: 0.4427 - val_loss: 8.5155 - val_acc: 0.0278\n",
      "Epoch 535/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.0172e-05 - acc: 0.4427 - val_loss: 8.6786 - val_acc: 0.0278\n",
      "Epoch 536/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.5400e-05 - acc: 0.4427 - val_loss: 8.6470 - val_acc: 0.0278\n",
      "Epoch 537/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 5ms/step - loss: 7.2228e-05 - acc: 0.4427 - val_loss: 8.6620 - val_acc: 0.0278\n",
      "Epoch 538/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.9896e-05 - acc: 0.4427 - val_loss: 8.6287 - val_acc: 0.0278\n",
      "Epoch 539/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.0242e-05 - acc: 0.4427 - val_loss: 8.5848 - val_acc: 0.0278\n",
      "Epoch 540/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 7.0387e-05 - acc: 0.4427 - val_loss: 8.6287 - val_acc: 0.0278\n",
      "Epoch 541/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 7.2386e-05 - acc: 0.4427 - val_loss: 8.6862 - val_acc: 0.0278\n",
      "Epoch 542/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.9723e-05 - acc: 0.4427 - val_loss: 8.6728 - val_acc: 0.0278\n",
      "Epoch 543/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.6801e-05 - acc: 0.4427 - val_loss: 8.6228 - val_acc: 0.0278\n",
      "Epoch 544/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.4369e-05 - acc: 0.4427 - val_loss: 8.6766 - val_acc: 0.0278\n",
      "Epoch 545/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.3097e-05 - acc: 0.4427 - val_loss: 8.5797 - val_acc: 0.0278\n",
      "Epoch 546/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.3189e-05 - acc: 0.4427 - val_loss: 8.7097 - val_acc: 0.0278\n",
      "Epoch 547/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.1366e-05 - acc: 0.4427 - val_loss: 8.7447 - val_acc: 0.0278\n",
      "Epoch 548/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.1909e-05 - acc: 0.4427 - val_loss: 8.4518 - val_acc: 0.0278\n",
      "Epoch 549/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.2904e-05 - acc: 0.4427 - val_loss: 8.6505 - val_acc: 0.0278\n",
      "Epoch 550/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0262e-05 - acc: 0.4427 - val_loss: 8.6967 - val_acc: 0.0278\n",
      "Epoch 551/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.8833e-05 - acc: 0.4427 - val_loss: 8.5112 - val_acc: 0.0278\n",
      "Epoch 552/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.7411e-05 - acc: 0.4427 - val_loss: 8.7086 - val_acc: 0.0278\n",
      "Epoch 553/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.6256e-05 - acc: 0.4427 - val_loss: 8.6777 - val_acc: 0.0278\n",
      "Epoch 554/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.5430e-05 - acc: 0.4427 - val_loss: 8.6157 - val_acc: 0.0278\n",
      "Epoch 555/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.6113e-05 - acc: 0.4427 - val_loss: 8.7377 - val_acc: 0.0278\n",
      "Epoch 556/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.5690e-05 - acc: 0.4427 - val_loss: 8.7400 - val_acc: 0.0278\n",
      "Epoch 557/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.3193e-05 - acc: 0.4427 - val_loss: 8.6223 - val_acc: 0.0278\n",
      "Epoch 558/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.2038e-05 - acc: 0.4427 - val_loss: 8.5957 - val_acc: 0.0278\n",
      "Epoch 559/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.0749e-05 - acc: 0.4427 - val_loss: 8.5248 - val_acc: 0.0278\n",
      "Epoch 560/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.2658e-05 - acc: 0.4427 - val_loss: 8.4572 - val_acc: 0.0278\n",
      "Epoch 561/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.0439e-05 - acc: 0.4427 - val_loss: 8.7096 - val_acc: 0.0278\n",
      "Epoch 562/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.1539e-05 - acc: 0.4427 - val_loss: 8.6652 - val_acc: 0.0278\n",
      "Epoch 563/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 4.9504e-05 - acc: 0.4427 - val_loss: 8.5717 - val_acc: 0.0278\n",
      "Epoch 564/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.7546e-05 - acc: 0.4427 - val_loss: 8.5647 - val_acc: 0.0278\n",
      "Epoch 565/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 4.6386e-05 - acc: 0.4427 - val_loss: 8.6654 - val_acc: 0.0278\n",
      "Epoch 566/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 4.5494e-05 - acc: 0.4427 - val_loss: 8.6125 - val_acc: 0.0278\n",
      "Epoch 567/1000\n",
      "131/131 [==============================] - 1s 11ms/step - loss: 4.4246e-05 - acc: 0.4427 - val_loss: 8.5715 - val_acc: 0.0278\n",
      "Epoch 568/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 4.3230e-05 - acc: 0.4427 - val_loss: 8.6329 - val_acc: 0.0278\n",
      "Epoch 569/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 4.2396e-05 - acc: 0.4427 - val_loss: 8.6482 - val_acc: 0.0278\n",
      "Epoch 570/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 4.9021e-05 - acc: 0.4427 - val_loss: 8.6014 - val_acc: 0.0278\n",
      "Epoch 571/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 4.2294e-05 - acc: 0.4427 - val_loss: 8.6160 - val_acc: 0.0278\n",
      "Epoch 572/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 4.1471e-05 - acc: 0.4427 - val_loss: 8.6388 - val_acc: 0.0278\n",
      "Epoch 573/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0436e-05 - acc: 0.4427 - val_loss: 8.6127 - val_acc: 0.0278\n",
      "Epoch 574/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0161e-05 - acc: 0.4427 - val_loss: 8.6014 - val_acc: 0.0278\n",
      "Epoch 575/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.9312e-05 - acc: 0.4427 - val_loss: 8.5986 - val_acc: 0.0278\n",
      "Epoch 576/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.8840e-05 - acc: 0.4427 - val_loss: 8.7082 - val_acc: 0.0278\n",
      "Epoch 577/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.8416e-05 - acc: 0.4427 - val_loss: 8.5796 - val_acc: 0.0278\n",
      "Epoch 578/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.8120e-05 - acc: 0.4427 - val_loss: 8.6570 - val_acc: 0.0278\n",
      "Epoch 579/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 3.7627e-05 - acc: 0.4427 - val_loss: 8.5422 - val_acc: 0.0278\n",
      "Epoch 580/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6894e-05 - acc: 0.4427 - val_loss: 8.5978 - val_acc: 0.0278\n",
      "Epoch 581/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6330e-05 - acc: 0.4427 - val_loss: 8.5007 - val_acc: 0.0278\n",
      "Epoch 582/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5839e-05 - acc: 0.4427 - val_loss: 8.7080 - val_acc: 0.0278\n",
      "Epoch 583/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5141e-05 - acc: 0.4427 - val_loss: 8.5923 - val_acc: 0.0278\n",
      "Epoch 584/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.8078e-05 - acc: 0.4427 - val_loss: 8.5597 - val_acc: 0.0278\n",
      "Epoch 585/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5482e-05 - acc: 0.4427 - val_loss: 8.7134 - val_acc: 0.0278\n",
      "Epoch 586/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.3994e-05 - acc: 0.4427 - val_loss: 8.5537 - val_acc: 0.0278\n",
      "Epoch 587/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2732e-05 - acc: 0.4427 - val_loss: 8.5980 - val_acc: 0.0278\n",
      "Epoch 588/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.2166e-05 - acc: 0.4427 - val_loss: 8.5757 - val_acc: 0.0278\n",
      "Epoch 589/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.2764e-05 - acc: 0.4427 - val_loss: 8.6150 - val_acc: 0.0278\n",
      "Epoch 590/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1914e-05 - acc: 0.4427 - val_loss: 8.5774 - val_acc: 0.0278\n",
      "Epoch 591/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1043e-05 - acc: 0.4427 - val_loss: 8.7334 - val_acc: 0.0278\n",
      "Epoch 592/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.4714e-05 - acc: 0.4427 - val_loss: 8.5815 - val_acc: 0.0278\n",
      "Epoch 593/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.3746e-05 - acc: 0.4427 - val_loss: 8.5572 - val_acc: 0.0278\n",
      "Epoch 594/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.0914e-05 - acc: 0.4427 - val_loss: 8.7755 - val_acc: 0.0278\n",
      "Epoch 595/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.9943e-05 - acc: 0.4427 - val_loss: 8.8065 - val_acc: 0.0278\n",
      "Epoch 596/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9327e-05 - acc: 0.4427 - val_loss: 8.5365 - val_acc: 0.0278\n",
      "Epoch 597/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9667e-05 - acc: 0.4427 - val_loss: 8.7076 - val_acc: 0.0278\n",
      "Epoch 598/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8491e-05 - acc: 0.4427 - val_loss: 8.5800 - val_acc: 0.0278\n",
      "Epoch 599/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2132e-05 - acc: 0.4427 - val_loss: 8.7167 - val_acc: 0.0278\n",
      "Epoch 600/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2801e-05 - acc: 0.4427 - val_loss: 8.6794 - val_acc: 0.0278\n",
      "Epoch 601/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.8310e-05 - acc: 0.4427 - val_loss: 8.7476 - val_acc: 0.0278\n",
      "Epoch 602/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.6961e-05 - acc: 0.4427 - val_loss: 8.5383 - val_acc: 0.0278\n",
      "Epoch 603/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.6685e-05 - acc: 0.4427 - val_loss: 8.7330 - val_acc: 0.0278\n",
      "Epoch 604/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.6005e-05 - acc: 0.4427 - val_loss: 8.7257 - val_acc: 0.0278\n",
      "Epoch 605/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.5985e-05 - acc: 0.4427 - val_loss: 8.7278 - val_acc: 0.0278\n",
      "Epoch 606/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5431e-05 - acc: 0.4427 - val_loss: 8.8379 - val_acc: 0.0278\n",
      "Epoch 607/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.5697e-05 - acc: 0.4427 - val_loss: 8.7700 - val_acc: 0.0278\n",
      "Epoch 608/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5087e-05 - acc: 0.4427 - val_loss: 8.6789 - val_acc: 0.0278\n",
      "Epoch 609/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.4962e-05 - acc: 0.4427 - val_loss: 8.8216 - val_acc: 0.0278\n",
      "Epoch 610/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.4005e-05 - acc: 0.4427 - val_loss: 8.6378 - val_acc: 0.0278\n",
      "Epoch 611/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.3905e-05 - acc: 0.4427 - val_loss: 8.5356 - val_acc: 0.0278\n",
      "Epoch 612/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 2.3552e-05 - acc: 0.4427 - val_loss: 8.8490 - val_acc: 0.0278\n",
      "Epoch 613/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 2.3161e-05 - acc: 0.4427 - val_loss: 8.6785 - val_acc: 0.0278\n",
      "Epoch 614/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2790e-05 - acc: 0.4427 - val_loss: 8.9011 - val_acc: 0.0278\n",
      "Epoch 615/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3700e-05 - acc: 0.4427 - val_loss: 8.6305 - val_acc: 0.0278\n",
      "Epoch 616/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2974e-05 - acc: 0.4427 - val_loss: 8.6761 - val_acc: 0.0278\n",
      "Epoch 617/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2766e-05 - acc: 0.4427 - val_loss: 8.7948 - val_acc: 0.0278\n",
      "Epoch 618/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2455e-05 - acc: 0.4427 - val_loss: 8.6399 - val_acc: 0.0278\n",
      "Epoch 619/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1823e-05 - acc: 0.4427 - val_loss: 8.6632 - val_acc: 0.0278\n",
      "Epoch 620/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.1974e-05 - acc: 0.4427 - val_loss: 8.5986 - val_acc: 0.0278\n",
      "Epoch 621/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3402e-05 - acc: 0.4427 - val_loss: 8.6672 - val_acc: 0.0278\n",
      "Epoch 622/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1619e-05 - acc: 0.4427 - val_loss: 8.6937 - val_acc: 0.0278\n",
      "Epoch 623/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.0841e-05 - acc: 0.4427 - val_loss: 8.6605 - val_acc: 0.0278\n",
      "Epoch 624/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.0448e-05 - acc: 0.4427 - val_loss: 8.5641 - val_acc: 0.0278\n",
      "Epoch 625/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.0447e-05 - acc: 0.4427 - val_loss: 8.8063 - val_acc: 0.0278\n",
      "Epoch 626/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.9817e-05 - acc: 0.4427 - val_loss: 8.6263 - val_acc: 0.0278\n",
      "Epoch 627/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.9457e-05 - acc: 0.4427 - val_loss: 8.6041 - val_acc: 0.0278\n",
      "Epoch 628/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.9304e-05 - acc: 0.4427 - val_loss: 8.8740 - val_acc: 0.0278\n",
      "Epoch 629/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.8903e-05 - acc: 0.4427 - val_loss: 8.6059 - val_acc: 0.0278\n",
      "Epoch 630/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8612e-05 - acc: 0.4427 - val_loss: 8.6639 - val_acc: 0.0278\n",
      "Epoch 631/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8526e-05 - acc: 0.4427 - val_loss: 8.5721 - val_acc: 0.0278\n",
      "Epoch 632/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8148e-05 - acc: 0.4427 - val_loss: 8.7582 - val_acc: 0.0278\n",
      "Epoch 633/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8019e-05 - acc: 0.4427 - val_loss: 8.8392 - val_acc: 0.0278\n",
      "Epoch 634/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.9518e-05 - acc: 0.4427 - val_loss: 8.7840 - val_acc: 0.0278\n",
      "Epoch 635/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8300e-05 - acc: 0.4427 - val_loss: 8.7367 - val_acc: 0.0278\n",
      "Epoch 636/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8184e-05 - acc: 0.4427 - val_loss: 8.6807 - val_acc: 0.0278\n",
      "Epoch 637/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.7274e-05 - acc: 0.4427 - val_loss: 8.6629 - val_acc: 0.0278\n",
      "Epoch 638/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.7086e-05 - acc: 0.4427 - val_loss: 8.7567 - val_acc: 0.0278\n",
      "Epoch 639/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.6743e-05 - acc: 0.4427 - val_loss: 8.6489 - val_acc: 0.0278\n",
      "Epoch 640/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.6864e-05 - acc: 0.4427 - val_loss: 8.5578 - val_acc: 0.0278\n",
      "Epoch 641/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.9353e-05 - acc: 0.4427 - val_loss: 8.7356 - val_acc: 0.0278\n",
      "Epoch 642/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.6535e-05 - acc: 0.4427 - val_loss: 8.6934 - val_acc: 0.0278\n",
      "Epoch 643/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5988e-05 - acc: 0.4427 - val_loss: 8.7079 - val_acc: 0.0278\n",
      "Epoch 644/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.6773e-05 - acc: 0.4427 - val_loss: 8.5923 - val_acc: 0.0278\n",
      "Epoch 645/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.0166e-05 - acc: 0.4427 - val_loss: 8.6742 - val_acc: 0.0278\n",
      "Epoch 646/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.6371e-05 - acc: 0.4427 - val_loss: 8.7316 - val_acc: 0.0278\n",
      "Epoch 647/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5783e-05 - acc: 0.4427 - val_loss: 8.7149 - val_acc: 0.0278\n",
      "Epoch 648/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.8930e-05 - acc: 0.4427 - val_loss: 8.5984 - val_acc: 0.0278\n",
      "Epoch 649/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.5440e-05 - acc: 0.4427 - val_loss: 8.5691 - val_acc: 0.0278\n",
      "Epoch 650/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.5201e-05 - acc: 0.4427 - val_loss: 8.6980 - val_acc: 0.0278\n",
      "Epoch 651/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.4779e-05 - acc: 0.4427 - val_loss: 8.6138 - val_acc: 0.0278\n",
      "Epoch 652/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.5041e-05 - acc: 0.4427 - val_loss: 8.5768 - val_acc: 0.0278\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4449e-05 - acc: 0.4427 - val_loss: 8.6290 - val_acc: 0.0278\n",
      "Epoch 654/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4223e-05 - acc: 0.4427 - val_loss: 8.6581 - val_acc: 0.0278\n",
      "Epoch 655/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.4270e-05 - acc: 0.4427 - val_loss: 8.8103 - val_acc: 0.0278\n",
      "Epoch 656/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3981e-05 - acc: 0.4427 - val_loss: 8.7942 - val_acc: 0.0278\n",
      "Epoch 657/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.4065e-05 - acc: 0.4427 - val_loss: 8.7250 - val_acc: 0.0278\n",
      "Epoch 658/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.2608e-05 - acc: 0.4427 - val_loss: 8.4896 - val_acc: 0.0278\n",
      "Epoch 659/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.8169e-05 - acc: 0.4427 - val_loss: 8.6073 - val_acc: 0.0278\n",
      "Epoch 660/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.4729e-05 - acc: 0.4427 - val_loss: 8.5757 - val_acc: 0.0278\n",
      "Epoch 661/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.4046e-05 - acc: 0.4427 - val_loss: 8.5624 - val_acc: 0.0278\n",
      "Epoch 662/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3708e-05 - acc: 0.4427 - val_loss: 8.5185 - val_acc: 0.0278\n",
      "Epoch 663/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3488e-05 - acc: 0.4427 - val_loss: 8.5101 - val_acc: 0.0278\n",
      "Epoch 664/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.3160e-05 - acc: 0.4427 - val_loss: 8.5098 - val_acc: 0.0278\n",
      "Epoch 665/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.2946e-05 - acc: 0.4427 - val_loss: 8.5206 - val_acc: 0.0278\n",
      "Epoch 666/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.2800e-05 - acc: 0.4427 - val_loss: 8.5311 - val_acc: 0.0278\n",
      "Epoch 667/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.2593e-05 - acc: 0.4427 - val_loss: 8.5441 - val_acc: 0.0278\n",
      "Epoch 668/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2619e-05 - acc: 0.4427 - val_loss: 8.5401 - val_acc: 0.0278\n",
      "Epoch 669/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.2473e-05 - acc: 0.4427 - val_loss: 8.5638 - val_acc: 0.0278\n",
      "Epoch 670/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.2320e-05 - acc: 0.4427 - val_loss: 8.5239 - val_acc: 0.0278\n",
      "Epoch 671/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.2694e-05 - acc: 0.4427 - val_loss: 8.7684 - val_acc: 0.0278\n",
      "Epoch 672/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2116e-05 - acc: 0.4427 - val_loss: 8.6579 - val_acc: 0.0278\n",
      "Epoch 673/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2166e-05 - acc: 0.4427 - val_loss: 8.6947 - val_acc: 0.0278\n",
      "Epoch 674/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.2035e-05 - acc: 0.4427 - val_loss: 8.6568 - val_acc: 0.0278\n",
      "Epoch 675/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1721e-05 - acc: 0.4427 - val_loss: 8.6434 - val_acc: 0.0278\n",
      "Epoch 676/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1549e-05 - acc: 0.4427 - val_loss: 8.6971 - val_acc: 0.0278\n",
      "Epoch 677/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1455e-05 - acc: 0.4427 - val_loss: 8.6293 - val_acc: 0.0278\n",
      "Epoch 678/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1220e-05 - acc: 0.4427 - val_loss: 8.5418 - val_acc: 0.0278\n",
      "Epoch 679/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1183e-05 - acc: 0.4427 - val_loss: 8.5446 - val_acc: 0.0278\n",
      "Epoch 680/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.1449e-05 - acc: 0.4427 - val_loss: 8.6417 - val_acc: 0.0278\n",
      "Epoch 681/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 1.1482e-05 - acc: 0.4427 - val_loss: 8.5756 - val_acc: 0.0278\n",
      "Epoch 682/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0970e-05 - acc: 0.4427 - val_loss: 8.5931 - val_acc: 0.0278\n",
      "Epoch 683/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 1.0726e-05 - acc: 0.4427 - val_loss: 8.5526 - val_acc: 0.0278\n",
      "Epoch 684/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 1.0928e-05 - acc: 0.4427 - val_loss: 8.5869 - val_acc: 0.0278\n",
      "Epoch 685/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 1.0795e-05 - acc: 0.4427 - val_loss: 8.9113 - val_acc: 0.0278\n",
      "Epoch 686/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.1026e-05 - acc: 0.4427 - val_loss: 8.7816 - val_acc: 0.0278\n",
      "Epoch 687/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0400e-05 - acc: 0.4427 - val_loss: 8.8148 - val_acc: 0.0278\n",
      "Epoch 688/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0249e-05 - acc: 0.4427 - val_loss: 8.8069 - val_acc: 0.0278\n",
      "Epoch 689/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0231e-05 - acc: 0.4427 - val_loss: 8.7470 - val_acc: 0.0278\n",
      "Epoch 690/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0152e-05 - acc: 0.4427 - val_loss: 8.7733 - val_acc: 0.0278\n",
      "Epoch 691/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.0070e-05 - acc: 0.4427 - val_loss: 8.7628 - val_acc: 0.0278\n",
      "Epoch 692/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.9019e-06 - acc: 0.4427 - val_loss: 8.7444 - val_acc: 0.0278\n",
      "Epoch 693/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 9.7880e-06 - acc: 0.4427 - val_loss: 8.7436 - val_acc: 0.0278\n",
      "Epoch 694/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 9.7934e-06 - acc: 0.4427 - val_loss: 8.7299 - val_acc: 0.0278\n",
      "Epoch 695/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 9.5997e-06 - acc: 0.4427 - val_loss: 8.7053 - val_acc: 0.0278\n",
      "Epoch 696/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 9.5227e-06 - acc: 0.4427 - val_loss: 8.7651 - val_acc: 0.0278\n",
      "Epoch 697/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 9.5785e-06 - acc: 0.4427 - val_loss: 8.8918 - val_acc: 0.0278\n",
      "Epoch 698/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.7958e-06 - acc: 0.4427 - val_loss: 8.6891 - val_acc: 0.0278\n",
      "Epoch 699/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.6758e-06 - acc: 0.4427 - val_loss: 8.6350 - val_acc: 0.0278\n",
      "Epoch 700/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.2182e-06 - acc: 0.4427 - val_loss: 8.8365 - val_acc: 0.0278\n",
      "Epoch 701/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.2111e-06 - acc: 0.4427 - val_loss: 8.7454 - val_acc: 0.0278\n",
      "Epoch 702/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.1715e-06 - acc: 0.4427 - val_loss: 8.6548 - val_acc: 0.0278\n",
      "Epoch 703/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 9.0641e-06 - acc: 0.4427 - val_loss: 8.7476 - val_acc: 0.0278\n",
      "Epoch 704/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.9839e-06 - acc: 0.4427 - val_loss: 8.7910 - val_acc: 0.0278\n",
      "Epoch 705/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 1.0874e-05 - acc: 0.4427 - val_loss: 8.6757 - val_acc: 0.0278\n",
      "Epoch 706/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 9.3843e-06 - acc: 0.4427 - val_loss: 8.6762 - val_acc: 0.0278\n",
      "Epoch 707/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 1.1625e-05 - acc: 0.4427 - val_loss: 8.7274 - val_acc: 0.0278\n",
      "Epoch 708/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 9.5105e-06 - acc: 0.4427 - val_loss: 8.7735 - val_acc: 0.0278\n",
      "Epoch 709/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.7729e-06 - acc: 0.4427 - val_loss: 8.7137 - val_acc: 0.0278\n",
      "Epoch 710/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.5876e-06 - acc: 0.4427 - val_loss: 8.7146 - val_acc: 0.0278\n",
      "Epoch 711/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.5036e-06 - acc: 0.4427 - val_loss: 8.7350 - val_acc: 0.0278\n",
      "Epoch 712/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 8.4021e-06 - acc: 0.4427 - val_loss: 8.7081 - val_acc: 0.0278\n",
      "Epoch 713/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.3674e-06 - acc: 0.4427 - val_loss: 8.7481 - val_acc: 0.0278\n",
      "Epoch 714/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 8.1805e-06 - acc: 0.4427 - val_loss: 8.7045 - val_acc: 0.0278\n",
      "Epoch 715/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 8.1182e-06 - acc: 0.4427 - val_loss: 8.7380 - val_acc: 0.0278\n",
      "Epoch 716/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.0715e-06 - acc: 0.4427 - val_loss: 8.7046 - val_acc: 0.0278\n",
      "Epoch 717/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.0421e-06 - acc: 0.4427 - val_loss: 8.7041 - val_acc: 0.0278\n",
      "Epoch 718/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.0218e-06 - acc: 0.4427 - val_loss: 8.7024 - val_acc: 0.0278\n",
      "Epoch 719/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.8870e-06 - acc: 0.4427 - val_loss: 8.6992 - val_acc: 0.0278\n",
      "Epoch 720/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.8120e-06 - acc: 0.4427 - val_loss: 8.7332 - val_acc: 0.0278\n",
      "Epoch 721/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 8.0316e-06 - acc: 0.4427 - val_loss: 8.6936 - val_acc: 0.0278\n",
      "Epoch 722/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.8245e-06 - acc: 0.4427 - val_loss: 8.7266 - val_acc: 0.0278\n",
      "Epoch 723/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.7425e-06 - acc: 0.4427 - val_loss: 8.7350 - val_acc: 0.0278\n",
      "Epoch 724/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.6792e-06 - acc: 0.4427 - val_loss: 8.6957 - val_acc: 0.0278\n",
      "Epoch 725/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.5397e-06 - acc: 0.4427 - val_loss: 8.6809 - val_acc: 0.0278\n",
      "Epoch 726/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.5419e-06 - acc: 0.4427 - val_loss: 8.7078 - val_acc: 0.0278\n",
      "Epoch 727/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.5362e-06 - acc: 0.4427 - val_loss: 8.6960 - val_acc: 0.0278\n",
      "Epoch 728/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.3446e-06 - acc: 0.4427 - val_loss: 8.6595 - val_acc: 0.0278\n",
      "Epoch 729/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.3922e-06 - acc: 0.4427 - val_loss: 8.6884 - val_acc: 0.0278\n",
      "Epoch 730/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.1819e-06 - acc: 0.4427 - val_loss: 8.6839 - val_acc: 0.0278\n",
      "Epoch 731/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.1276e-06 - acc: 0.4427 - val_loss: 8.7089 - val_acc: 0.0278\n",
      "Epoch 732/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.3864e-06 - acc: 0.4427 - val_loss: 8.6794 - val_acc: 0.0278\n",
      "Epoch 733/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.3906e-06 - acc: 0.4427 - val_loss: 8.6711 - val_acc: 0.0278\n",
      "Epoch 734/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 7.1827e-06 - acc: 0.4427 - val_loss: 8.7337 - val_acc: 0.0278\n",
      "Epoch 735/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 7.0551e-06 - acc: 0.4427 - val_loss: 8.7270 - val_acc: 0.0278\n",
      "Epoch 736/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.9536e-06 - acc: 0.4427 - val_loss: 8.6687 - val_acc: 0.0278\n",
      "Epoch 737/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.8675e-06 - acc: 0.4427 - val_loss: 8.7143 - val_acc: 0.0278\n",
      "Epoch 738/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 6.8130e-06 - acc: 0.4427 - val_loss: 8.7092 - val_acc: 0.0278\n",
      "Epoch 739/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 6.7482e-06 - acc: 0.4427 - val_loss: 8.6132 - val_acc: 0.0278\n",
      "Epoch 740/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.7325e-06 - acc: 0.4427 - val_loss: 8.7751 - val_acc: 0.0278\n",
      "Epoch 741/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 6.7811e-06 - acc: 0.4427 - val_loss: 8.6740 - val_acc: 0.0278\n",
      "Epoch 742/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.8521e-06 - acc: 0.4427 - val_loss: 8.7234 - val_acc: 0.0278\n",
      "Epoch 743/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.7202e-06 - acc: 0.4427 - val_loss: 8.7100 - val_acc: 0.0278\n",
      "Epoch 744/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 7.2525e-06 - acc: 0.4427 - val_loss: 8.8181 - val_acc: 0.0278\n",
      "Epoch 745/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.8180e-06 - acc: 0.4427 - val_loss: 8.7402 - val_acc: 0.0278\n",
      "Epoch 746/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.5683e-06 - acc: 0.4427 - val_loss: 8.7255 - val_acc: 0.0278\n",
      "Epoch 747/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.4414e-06 - acc: 0.4427 - val_loss: 8.7103 - val_acc: 0.0278\n",
      "Epoch 748/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.3077e-06 - acc: 0.4427 - val_loss: 8.7727 - val_acc: 0.0278\n",
      "Epoch 749/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.4464e-06 - acc: 0.4427 - val_loss: 8.6999 - val_acc: 0.0278\n",
      "Epoch 750/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.2724e-06 - acc: 0.4427 - val_loss: 8.6911 - val_acc: 0.0278\n",
      "Epoch 751/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.2053e-06 - acc: 0.4427 - val_loss: 8.7593 - val_acc: 0.0278\n",
      "Epoch 752/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 6.1667e-06 - acc: 0.4427 - val_loss: 8.7164 - val_acc: 0.0278\n",
      "Epoch 753/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 6.1006e-06 - acc: 0.4427 - val_loss: 8.7161 - val_acc: 0.0278\n",
      "Epoch 754/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 6.3420e-06 - acc: 0.4427 - val_loss: 8.6236 - val_acc: 0.0278\n",
      "Epoch 755/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 6.3364e-06 - acc: 0.4427 - val_loss: 8.7504 - val_acc: 0.0278\n",
      "Epoch 756/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.2809e-06 - acc: 0.4427 - val_loss: 8.6793 - val_acc: 0.0278\n",
      "Epoch 757/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 6.0567e-06 - acc: 0.4427 - val_loss: 8.6908 - val_acc: 0.0278\n",
      "Epoch 758/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.9274e-06 - acc: 0.4427 - val_loss: 8.6536 - val_acc: 0.0278\n",
      "Epoch 759/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0089e-06 - acc: 0.4427 - val_loss: 8.6990 - val_acc: 0.0278\n",
      "Epoch 760/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0119e-06 - acc: 0.4427 - val_loss: 8.6660 - val_acc: 0.0278\n",
      "Epoch 761/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.9053e-06 - acc: 0.4427 - val_loss: 8.6749 - val_acc: 0.0278\n",
      "Epoch 762/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.8362e-06 - acc: 0.4427 - val_loss: 8.6841 - val_acc: 0.0278\n",
      "Epoch 763/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.7366e-06 - acc: 0.4427 - val_loss: 8.6913 - val_acc: 0.0278\n",
      "Epoch 764/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.7035e-06 - acc: 0.4427 - val_loss: 8.6742 - val_acc: 0.0278\n",
      "Epoch 765/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.7034e-06 - acc: 0.4427 - val_loss: 8.7116 - val_acc: 0.0278\n",
      "Epoch 766/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.6904e-06 - acc: 0.4427 - val_loss: 8.6351 - val_acc: 0.0278\n",
      "Epoch 767/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 6.0424e-06 - acc: 0.4427 - val_loss: 8.6662 - val_acc: 0.0278\n",
      "Epoch 768/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.6052e-06 - acc: 0.4427 - val_loss: 8.6878 - val_acc: 0.0278\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 5ms/step - loss: 5.5309e-06 - acc: 0.4427 - val_loss: 8.6758 - val_acc: 0.0278\n",
      "Epoch 770/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.4974e-06 - acc: 0.4427 - val_loss: 8.6791 - val_acc: 0.0278\n",
      "Epoch 771/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.4711e-06 - acc: 0.4427 - val_loss: 8.6175 - val_acc: 0.0278\n",
      "Epoch 772/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.4484e-06 - acc: 0.4427 - val_loss: 8.7080 - val_acc: 0.0278\n",
      "Epoch 773/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.4296e-06 - acc: 0.4427 - val_loss: 8.6954 - val_acc: 0.0278\n",
      "Epoch 774/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.5753e-06 - acc: 0.4427 - val_loss: 8.6693 - val_acc: 0.0278\n",
      "Epoch 775/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 5.6771e-06 - acc: 0.4427 - val_loss: 8.6963 - val_acc: 0.0278\n",
      "Epoch 776/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.3106e-06 - acc: 0.4427 - val_loss: 8.7045 - val_acc: 0.0278\n",
      "Epoch 777/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.2581e-06 - acc: 0.4427 - val_loss: 8.6617 - val_acc: 0.0278\n",
      "Epoch 778/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 5.2493e-06 - acc: 0.4427 - val_loss: 8.6371 - val_acc: 0.0278\n",
      "Epoch 779/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 5.1903e-06 - acc: 0.4427 - val_loss: 8.6850 - val_acc: 0.0278\n",
      "Epoch 780/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 5.1497e-06 - acc: 0.4427 - val_loss: 8.6803 - val_acc: 0.0278\n",
      "Epoch 781/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.1934e-06 - acc: 0.4427 - val_loss: 8.6633 - val_acc: 0.0278\n",
      "Epoch 782/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.2025e-06 - acc: 0.4427 - val_loss: 8.6043 - val_acc: 0.0278\n",
      "Epoch 783/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.2800e-06 - acc: 0.4427 - val_loss: 8.6976 - val_acc: 0.0278\n",
      "Epoch 784/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.1002e-06 - acc: 0.4427 - val_loss: 8.6998 - val_acc: 0.0278\n",
      "Epoch 785/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.0377e-06 - acc: 0.4427 - val_loss: 8.6969 - val_acc: 0.0278\n",
      "Epoch 786/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.0072e-06 - acc: 0.4427 - val_loss: 8.6744 - val_acc: 0.0278\n",
      "Epoch 787/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.0149e-06 - acc: 0.4427 - val_loss: 8.6485 - val_acc: 0.0278\n",
      "Epoch 788/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 4.9590e-06 - acc: 0.4427 - val_loss: 8.6772 - val_acc: 0.0278\n",
      "Epoch 789/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.9985e-06 - acc: 0.4427 - val_loss: 8.6047 - val_acc: 0.0278\n",
      "Epoch 790/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 5.0094e-06 - acc: 0.4427 - val_loss: 8.7478 - val_acc: 0.0278\n",
      "Epoch 791/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 5.0411e-06 - acc: 0.4427 - val_loss: 8.6615 - val_acc: 0.0278\n",
      "Epoch 792/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.9102e-06 - acc: 0.4427 - val_loss: 8.6590 - val_acc: 0.0278\n",
      "Epoch 793/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.8149e-06 - acc: 0.4427 - val_loss: 8.6311 - val_acc: 0.0278\n",
      "Epoch 794/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.9020e-06 - acc: 0.4427 - val_loss: 8.6902 - val_acc: 0.0278\n",
      "Epoch 795/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.7320e-06 - acc: 0.4427 - val_loss: 8.6915 - val_acc: 0.0278\n",
      "Epoch 796/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 4.6954e-06 - acc: 0.4427 - val_loss: 8.6845 - val_acc: 0.0278\n",
      "Epoch 797/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.6716e-06 - acc: 0.4427 - val_loss: 8.7640 - val_acc: 0.0278\n",
      "Epoch 798/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.9040e-06 - acc: 0.4427 - val_loss: 8.6925 - val_acc: 0.0278\n",
      "Epoch 799/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.7660e-06 - acc: 0.4427 - val_loss: 8.5980 - val_acc: 0.0278\n",
      "Epoch 800/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 4.9739e-06 - acc: 0.4427 - val_loss: 8.6793 - val_acc: 0.0278\n",
      "Epoch 801/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.7264e-06 - acc: 0.4427 - val_loss: 8.6616 - val_acc: 0.0278\n",
      "Epoch 802/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.6034e-06 - acc: 0.4427 - val_loss: 8.6790 - val_acc: 0.0278\n",
      "Epoch 803/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.5460e-06 - acc: 0.4427 - val_loss: 8.7076 - val_acc: 0.0278\n",
      "Epoch 804/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.5872e-06 - acc: 0.4427 - val_loss: 8.6352 - val_acc: 0.0278\n",
      "Epoch 805/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.5058e-06 - acc: 0.4427 - val_loss: 8.6525 - val_acc: 0.0278\n",
      "Epoch 806/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.4754e-06 - acc: 0.4427 - val_loss: 8.6484 - val_acc: 0.0278\n",
      "Epoch 807/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.4809e-06 - acc: 0.4427 - val_loss: 8.6588 - val_acc: 0.0278\n",
      "Epoch 808/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.4013e-06 - acc: 0.4427 - val_loss: 8.7130 - val_acc: 0.0278\n",
      "Epoch 809/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.4627e-06 - acc: 0.4427 - val_loss: 8.7370 - val_acc: 0.0278\n",
      "Epoch 810/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.3954e-06 - acc: 0.4427 - val_loss: 8.6602 - val_acc: 0.0278\n",
      "Epoch 811/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.4184e-06 - acc: 0.4427 - val_loss: 8.6886 - val_acc: 0.0278\n",
      "Epoch 812/1000\n",
      "131/131 [==============================] - ETA: 0s - loss: 4.5942e-06 - acc: 0.442 - 1s 5ms/step - loss: 4.5757e-06 - acc: 0.4427 - val_loss: 8.7382 - val_acc: 0.0278\n",
      "Epoch 813/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.3915e-06 - acc: 0.4427 - val_loss: 8.6862 - val_acc: 0.0278\n",
      "Epoch 814/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.3062e-06 - acc: 0.4427 - val_loss: 8.7449 - val_acc: 0.0278\n",
      "Epoch 815/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 4.2920e-06 - acc: 0.4427 - val_loss: 8.6815 - val_acc: 0.0278\n",
      "Epoch 816/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.2298e-06 - acc: 0.4427 - val_loss: 8.7016 - val_acc: 0.0278\n",
      "Epoch 817/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 4.2166e-06 - acc: 0.4427 - val_loss: 8.6653 - val_acc: 0.0278\n",
      "Epoch 818/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 4.2152e-06 - acc: 0.4427 - val_loss: 8.6989 - val_acc: 0.0278\n",
      "Epoch 819/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.1950e-06 - acc: 0.4427 - val_loss: 8.7108 - val_acc: 0.0278\n",
      "Epoch 820/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.1846e-06 - acc: 0.4427 - val_loss: 8.7597 - val_acc: 0.0278\n",
      "Epoch 821/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.2827e-06 - acc: 0.4427 - val_loss: 8.6709 - val_acc: 0.0278\n",
      "Epoch 822/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.1208e-06 - acc: 0.4427 - val_loss: 8.7393 - val_acc: 0.0278\n",
      "Epoch 823/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0892e-06 - acc: 0.4427 - val_loss: 8.7493 - val_acc: 0.0278\n",
      "Epoch 824/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0895e-06 - acc: 0.4427 - val_loss: 8.6565 - val_acc: 0.0278\n",
      "Epoch 825/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0778e-06 - acc: 0.4427 - val_loss: 8.7070 - val_acc: 0.0278\n",
      "Epoch 826/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0594e-06 - acc: 0.4427 - val_loss: 8.7210 - val_acc: 0.0278\n",
      "Epoch 827/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.9958e-06 - acc: 0.4427 - val_loss: 8.7309 - val_acc: 0.0278\n",
      "Epoch 828/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.0985e-06 - acc: 0.4427 - val_loss: 8.6968 - val_acc: 0.0278\n",
      "Epoch 829/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 4.1249e-06 - acc: 0.4427 - val_loss: 8.8485 - val_acc: 0.0278\n",
      "Epoch 830/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 4.0907e-06 - acc: 0.4427 - val_loss: 8.7583 - val_acc: 0.0278\n",
      "Epoch 831/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.9829e-06 - acc: 0.4427 - val_loss: 8.7120 - val_acc: 0.0278\n",
      "Epoch 832/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 3.9179e-06 - acc: 0.4427 - val_loss: 8.7309 - val_acc: 0.0278\n",
      "Epoch 833/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 4.0006e-06 - acc: 0.4427 - val_loss: 8.7474 - val_acc: 0.0278\n",
      "Epoch 834/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 3.8870e-06 - acc: 0.4427 - val_loss: 8.7751 - val_acc: 0.0278\n",
      "Epoch 835/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.8836e-06 - acc: 0.4427 - val_loss: 8.7512 - val_acc: 0.0278\n",
      "Epoch 836/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.8342e-06 - acc: 0.4427 - val_loss: 8.7284 - val_acc: 0.0278\n",
      "Epoch 837/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 3.8318e-06 - acc: 0.4427 - val_loss: 8.7600 - val_acc: 0.0278\n",
      "Epoch 838/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.8029e-06 - acc: 0.4427 - val_loss: 8.6911 - val_acc: 0.0278\n",
      "Epoch 839/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.8104e-06 - acc: 0.4427 - val_loss: 8.7853 - val_acc: 0.0278\n",
      "Epoch 840/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 4.1301e-06 - acc: 0.4427 - val_loss: 8.7057 - val_acc: 0.0278\n",
      "Epoch 841/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.8868e-06 - acc: 0.4427 - val_loss: 8.7418 - val_acc: 0.0278\n",
      "Epoch 842/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.8688e-06 - acc: 0.4427 - val_loss: 8.8284 - val_acc: 0.0278\n",
      "Epoch 843/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.7933e-06 - acc: 0.4427 - val_loss: 8.7241 - val_acc: 0.0278\n",
      "Epoch 844/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.7389e-06 - acc: 0.4427 - val_loss: 8.7551 - val_acc: 0.0278\n",
      "Epoch 845/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.7124e-06 - acc: 0.4427 - val_loss: 8.7255 - val_acc: 0.0278\n",
      "Epoch 846/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.7095e-06 - acc: 0.4427 - val_loss: 8.7593 - val_acc: 0.0278\n",
      "Epoch 847/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.7837e-06 - acc: 0.4427 - val_loss: 8.7150 - val_acc: 0.0278\n",
      "Epoch 848/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 3.7647e-06 - acc: 0.4427 - val_loss: 8.7834 - val_acc: 0.0278\n",
      "Epoch 849/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.6806e-06 - acc: 0.4427 - val_loss: 8.7001 - val_acc: 0.0278\n",
      "Epoch 850/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6241e-06 - acc: 0.4427 - val_loss: 8.7590 - val_acc: 0.0278\n",
      "Epoch 851/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 3.5809e-06 - acc: 0.4427 - val_loss: 8.7851 - val_acc: 0.0278\n",
      "Epoch 852/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.6315e-06 - acc: 0.4427 - val_loss: 8.7435 - val_acc: 0.0278\n",
      "Epoch 853/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.5628e-06 - acc: 0.4427 - val_loss: 8.7611 - val_acc: 0.0278\n",
      "Epoch 854/1000\n",
      "131/131 [==============================] - 1s 9ms/step - loss: 3.5613e-06 - acc: 0.4427 - val_loss: 8.6718 - val_acc: 0.0278\n",
      "Epoch 855/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.5405e-06 - acc: 0.4427 - val_loss: 8.7209 - val_acc: 0.0278\n",
      "Epoch 856/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5203e-06 - acc: 0.4427 - val_loss: 8.6993 - val_acc: 0.0278\n",
      "Epoch 857/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5757e-06 - acc: 0.4427 - val_loss: 8.7630 - val_acc: 0.0278\n",
      "Epoch 858/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.4886e-06 - acc: 0.4427 - val_loss: 8.7128 - val_acc: 0.0278\n",
      "Epoch 859/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.4445e-06 - acc: 0.4427 - val_loss: 8.7737 - val_acc: 0.0278\n",
      "Epoch 860/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 3.4448e-06 - acc: 0.4427 - val_loss: 8.8064 - val_acc: 0.0278\n",
      "Epoch 861/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.4413e-06 - acc: 0.4427 - val_loss: 8.7717 - val_acc: 0.0278\n",
      "Epoch 862/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 3.4331e-06 - acc: 0.4427 - val_loss: 8.7448 - val_acc: 0.0278\n",
      "Epoch 863/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.4082e-06 - acc: 0.4427 - val_loss: 8.8619 - val_acc: 0.0278\n",
      "Epoch 864/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.7021e-06 - acc: 0.4427 - val_loss: 8.8187 - val_acc: 0.0278\n",
      "Epoch 865/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.4070e-06 - acc: 0.4427 - val_loss: 8.7888 - val_acc: 0.0278\n",
      "Epoch 866/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.4257e-06 - acc: 0.4427 - val_loss: 8.8257 - val_acc: 0.0278\n",
      "Epoch 867/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.5890e-06 - acc: 0.4427 - val_loss: 8.7748 - val_acc: 0.0278\n",
      "Epoch 868/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.4262e-06 - acc: 0.4427 - val_loss: 8.7911 - val_acc: 0.0278\n",
      "Epoch 869/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.3320e-06 - acc: 0.4427 - val_loss: 8.7810 - val_acc: 0.0278\n",
      "Epoch 870/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.3306e-06 - acc: 0.4427 - val_loss: 8.7735 - val_acc: 0.0278\n",
      "Epoch 871/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2883e-06 - acc: 0.4427 - val_loss: 8.7539 - val_acc: 0.0278\n",
      "Epoch 872/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2903e-06 - acc: 0.4427 - val_loss: 8.7412 - val_acc: 0.0278\n",
      "Epoch 873/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2599e-06 - acc: 0.4427 - val_loss: 8.7953 - val_acc: 0.0278\n",
      "Epoch 874/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.2454e-06 - acc: 0.4427 - val_loss: 8.7424 - val_acc: 0.0278\n",
      "Epoch 875/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 3.2313e-06 - acc: 0.4427 - val_loss: 8.7415 - val_acc: 0.0278\n",
      "Epoch 876/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.2941e-06 - acc: 0.4427 - val_loss: 8.7876 - val_acc: 0.0278\n",
      "Epoch 877/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2134e-06 - acc: 0.4427 - val_loss: 8.7593 - val_acc: 0.0278\n",
      "Epoch 878/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.2974e-06 - acc: 0.4427 - val_loss: 8.7938 - val_acc: 0.0278\n",
      "Epoch 879/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.2919e-06 - acc: 0.4427 - val_loss: 8.8031 - val_acc: 0.0278\n",
      "Epoch 880/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.1947e-06 - acc: 0.4427 - val_loss: 8.8047 - val_acc: 0.0278\n",
      "Epoch 881/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 3.1511e-06 - acc: 0.4427 - val_loss: 8.7649 - val_acc: 0.0278\n",
      "Epoch 882/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.1380e-06 - acc: 0.4427 - val_loss: 8.8259 - val_acc: 0.0278\n",
      "Epoch 883/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2712e-06 - acc: 0.4427 - val_loss: 8.7171 - val_acc: 0.0278\n",
      "Epoch 884/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1922e-06 - acc: 0.4427 - val_loss: 8.7764 - val_acc: 0.0278\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 1s 4ms/step - loss: 3.2053e-06 - acc: 0.4427 - val_loss: 8.7697 - val_acc: 0.0278\n",
      "Epoch 886/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 3.1494e-06 - acc: 0.4427 - val_loss: 8.7632 - val_acc: 0.0278\n",
      "Epoch 887/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1343e-06 - acc: 0.4427 - val_loss: 8.7745 - val_acc: 0.0278\n",
      "Epoch 888/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.0649e-06 - acc: 0.4427 - val_loss: 8.7779 - val_acc: 0.0278\n",
      "Epoch 889/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.1290e-06 - acc: 0.4427 - val_loss: 8.7614 - val_acc: 0.0278\n",
      "Epoch 890/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.0628e-06 - acc: 0.4427 - val_loss: 8.7863 - val_acc: 0.0278\n",
      "Epoch 891/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.0512e-06 - acc: 0.4427 - val_loss: 8.7713 - val_acc: 0.0278\n",
      "Epoch 892/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 3.0249e-06 - acc: 0.4427 - val_loss: 8.7623 - val_acc: 0.0278\n",
      "Epoch 893/1000\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 3.0233e-06 - acc: 0.4427 - val_loss: 8.7877 - val_acc: 0.0278\n",
      "Epoch 894/1000\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 3.0196e-06 - acc: 0.4427 - val_loss: 8.8052 - val_acc: 0.0278\n",
      "Epoch 895/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9924e-06 - acc: 0.4427 - val_loss: 8.8158 - val_acc: 0.0278\n",
      "Epoch 896/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.0919e-06 - acc: 0.4427 - val_loss: 8.7606 - val_acc: 0.0278\n",
      "Epoch 897/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 3.0080e-06 - acc: 0.4427 - val_loss: 8.8041 - val_acc: 0.0278\n",
      "Epoch 898/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9818e-06 - acc: 0.4427 - val_loss: 8.8030 - val_acc: 0.0278\n",
      "Epoch 899/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.9824e-06 - acc: 0.4427 - val_loss: 8.7479 - val_acc: 0.0278\n",
      "Epoch 900/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 2.9519e-06 - acc: 0.4427 - val_loss: 8.8135 - val_acc: 0.0278\n",
      "Epoch 901/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.9726e-06 - acc: 0.4427 - val_loss: 8.7816 - val_acc: 0.0278\n",
      "Epoch 902/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.9143e-06 - acc: 0.4427 - val_loss: 8.8090 - val_acc: 0.0278\n",
      "Epoch 903/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 2.8963e-06 - acc: 0.4427 - val_loss: 8.7797 - val_acc: 0.0278\n",
      "Epoch 904/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 2.8734e-06 - acc: 0.4427 - val_loss: 8.7835 - val_acc: 0.0278\n",
      "Epoch 905/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.8663e-06 - acc: 0.4427 - val_loss: 8.7929 - val_acc: 0.0278\n",
      "Epoch 906/1000\n",
      "131/131 [==============================] - 1s 7ms/step - loss: 2.8941e-06 - acc: 0.4427 - val_loss: 8.7754 - val_acc: 0.0278\n",
      "Epoch 907/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8541e-06 - acc: 0.4427 - val_loss: 8.7570 - val_acc: 0.0278\n",
      "Epoch 908/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8861e-06 - acc: 0.4427 - val_loss: 8.7760 - val_acc: 0.0278\n",
      "Epoch 909/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.8737e-06 - acc: 0.4427 - val_loss: 8.7074 - val_acc: 0.0278\n",
      "Epoch 910/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.8679e-06 - acc: 0.4427 - val_loss: 8.7617 - val_acc: 0.0278\n",
      "Epoch 911/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8319e-06 - acc: 0.4427 - val_loss: 8.8283 - val_acc: 0.0278\n",
      "Epoch 912/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.9174e-06 - acc: 0.4427 - val_loss: 8.7656 - val_acc: 0.0278\n",
      "Epoch 913/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.8703e-06 - acc: 0.4427 - val_loss: 8.8153 - val_acc: 0.0278\n",
      "Epoch 914/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8524e-06 - acc: 0.4427 - val_loss: 8.7713 - val_acc: 0.0278\n",
      "Epoch 915/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.9003e-06 - acc: 0.4427 - val_loss: 8.7656 - val_acc: 0.0278\n",
      "Epoch 916/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.8065e-06 - acc: 0.4427 - val_loss: 8.7620 - val_acc: 0.0278\n",
      "Epoch 917/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7598e-06 - acc: 0.4427 - val_loss: 8.7639 - val_acc: 0.0278\n",
      "Epoch 918/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7962e-06 - acc: 0.4427 - val_loss: 8.7718 - val_acc: 0.0278\n",
      "Epoch 919/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7448e-06 - acc: 0.4427 - val_loss: 8.8387 - val_acc: 0.0278\n",
      "Epoch 920/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7575e-06 - acc: 0.4427 - val_loss: 8.7598 - val_acc: 0.0278\n",
      "Epoch 921/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.7253e-06 - acc: 0.4427 - val_loss: 8.7629 - val_acc: 0.0278\n",
      "Epoch 922/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.7160e-06 - acc: 0.4427 - val_loss: 8.7376 - val_acc: 0.0278\n",
      "Epoch 923/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.7096e-06 - acc: 0.4427 - val_loss: 8.7184 - val_acc: 0.0278\n",
      "Epoch 924/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6911e-06 - acc: 0.4427 - val_loss: 8.7465 - val_acc: 0.0278\n",
      "Epoch 925/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.6867e-06 - acc: 0.4427 - val_loss: 8.7637 - val_acc: 0.0278\n",
      "Epoch 926/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6821e-06 - acc: 0.4427 - val_loss: 8.7508 - val_acc: 0.0278\n",
      "Epoch 927/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6624e-06 - acc: 0.4427 - val_loss: 8.7764 - val_acc: 0.0278\n",
      "Epoch 928/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.6574e-06 - acc: 0.4427 - val_loss: 8.7302 - val_acc: 0.0278\n",
      "Epoch 929/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6506e-06 - acc: 0.4427 - val_loss: 8.7928 - val_acc: 0.0278\n",
      "Epoch 930/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.6378e-06 - acc: 0.4427 - val_loss: 8.7515 - val_acc: 0.0278\n",
      "Epoch 931/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.6194e-06 - acc: 0.4427 - val_loss: 8.8150 - val_acc: 0.0278\n",
      "Epoch 932/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 3.1709e-06 - acc: 0.4427 - val_loss: 8.8197 - val_acc: 0.0278\n",
      "Epoch 933/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.9564e-06 - acc: 0.4427 - val_loss: 8.8001 - val_acc: 0.0278\n",
      "Epoch 934/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.6761e-06 - acc: 0.4427 - val_loss: 8.7315 - val_acc: 0.0278\n",
      "Epoch 935/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.6475e-06 - acc: 0.4427 - val_loss: 8.7751 - val_acc: 0.0278\n",
      "Epoch 936/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5938e-06 - acc: 0.4427 - val_loss: 8.7834 - val_acc: 0.0278\n",
      "Epoch 937/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.5764e-06 - acc: 0.4427 - val_loss: 8.7937 - val_acc: 0.0278\n",
      "Epoch 938/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5694e-06 - acc: 0.4427 - val_loss: 8.7796 - val_acc: 0.0278\n",
      "Epoch 939/1000\n",
      "131/131 [==============================] - 1s 10ms/step - loss: 2.5569e-06 - acc: 0.4427 - val_loss: 8.8190 - val_acc: 0.0278\n",
      "Epoch 940/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.6160e-06 - acc: 0.4427 - val_loss: 8.7486 - val_acc: 0.0278\n",
      "Epoch 941/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5534e-06 - acc: 0.4427 - val_loss: 8.7912 - val_acc: 0.0278\n",
      "Epoch 942/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5231e-06 - acc: 0.4427 - val_loss: 8.7646 - val_acc: 0.0278\n",
      "Epoch 943/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.5175e-06 - acc: 0.4427 - val_loss: 8.7737 - val_acc: 0.0278\n",
      "Epoch 944/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5123e-06 - acc: 0.4427 - val_loss: 8.7681 - val_acc: 0.0278\n",
      "Epoch 945/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5470e-06 - acc: 0.4427 - val_loss: 8.7664 - val_acc: 0.0278\n",
      "Epoch 946/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.5130e-06 - acc: 0.4427 - val_loss: 8.7821 - val_acc: 0.0278\n",
      "Epoch 947/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.5099e-06 - acc: 0.4427 - val_loss: 8.7539 - val_acc: 0.0278\n",
      "Epoch 948/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4994e-06 - acc: 0.4427 - val_loss: 8.7847 - val_acc: 0.0278\n",
      "Epoch 949/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5870e-06 - acc: 0.4427 - val_loss: 8.7602 - val_acc: 0.0278\n",
      "Epoch 950/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.4990e-06 - acc: 0.4427 - val_loss: 8.7844 - val_acc: 0.0278\n",
      "Epoch 951/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.4889e-06 - acc: 0.4427 - val_loss: 8.7869 - val_acc: 0.0278\n",
      "Epoch 952/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5028e-06 - acc: 0.4427 - val_loss: 8.7451 - val_acc: 0.0278\n",
      "Epoch 953/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.5147e-06 - acc: 0.4427 - val_loss: 8.7912 - val_acc: 0.0278\n",
      "Epoch 954/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4358e-06 - acc: 0.4427 - val_loss: 8.7833 - val_acc: 0.0278\n",
      "Epoch 955/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4631e-06 - acc: 0.4427 - val_loss: 8.8086 - val_acc: 0.0278\n",
      "Epoch 956/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.5769e-06 - acc: 0.4427 - val_loss: 8.8434 - val_acc: 0.0278\n",
      "Epoch 957/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4926e-06 - acc: 0.4427 - val_loss: 8.8232 - val_acc: 0.0278\n",
      "Epoch 958/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4263e-06 - acc: 0.4427 - val_loss: 8.8113 - val_acc: 0.0278\n",
      "Epoch 959/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4154e-06 - acc: 0.4427 - val_loss: 8.7768 - val_acc: 0.0278\n",
      "Epoch 960/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4103e-06 - acc: 0.4427 - val_loss: 8.7899 - val_acc: 0.0278\n",
      "Epoch 961/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.3870e-06 - acc: 0.4427 - val_loss: 8.7813 - val_acc: 0.0278\n",
      "Epoch 962/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.3790e-06 - acc: 0.4427 - val_loss: 8.7778 - val_acc: 0.0278\n",
      "Epoch 963/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3732e-06 - acc: 0.4427 - val_loss: 8.7971 - val_acc: 0.0278\n",
      "Epoch 964/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3605e-06 - acc: 0.4427 - val_loss: 8.7479 - val_acc: 0.0278\n",
      "Epoch 965/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3569e-06 - acc: 0.4427 - val_loss: 8.7485 - val_acc: 0.0278\n",
      "Epoch 966/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4685e-06 - acc: 0.4427 - val_loss: 8.7829 - val_acc: 0.0278\n",
      "Epoch 967/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3713e-06 - acc: 0.4427 - val_loss: 8.7954 - val_acc: 0.0278\n",
      "Epoch 968/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3355e-06 - acc: 0.4427 - val_loss: 8.7647 - val_acc: 0.0278\n",
      "Epoch 969/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.3237e-06 - acc: 0.4427 - val_loss: 8.7805 - val_acc: 0.0278\n",
      "Epoch 970/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.3340e-06 - acc: 0.4427 - val_loss: 8.8142 - val_acc: 0.0278\n",
      "Epoch 971/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3393e-06 - acc: 0.4427 - val_loss: 8.7887 - val_acc: 0.0278\n",
      "Epoch 972/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.3008e-06 - acc: 0.4427 - val_loss: 8.7742 - val_acc: 0.0278\n",
      "Epoch 973/1000\n",
      "131/131 [==============================] - 1s 8ms/step - loss: 2.2976e-06 - acc: 0.4427 - val_loss: 8.7760 - val_acc: 0.0278\n",
      "Epoch 974/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2821e-06 - acc: 0.4427 - val_loss: 8.7664 - val_acc: 0.0278\n",
      "Epoch 975/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.2703e-06 - acc: 0.4427 - val_loss: 8.7863 - val_acc: 0.0278\n",
      "Epoch 976/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2634e-06 - acc: 0.4427 - val_loss: 8.7827 - val_acc: 0.0278\n",
      "Epoch 977/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.2601e-06 - acc: 0.4427 - val_loss: 8.7630 - val_acc: 0.0278\n",
      "Epoch 978/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2599e-06 - acc: 0.4427 - val_loss: 8.7350 - val_acc: 0.0278\n",
      "Epoch 979/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2667e-06 - acc: 0.4427 - val_loss: 8.7697 - val_acc: 0.0278\n",
      "Epoch 980/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2632e-06 - acc: 0.4427 - val_loss: 8.7656 - val_acc: 0.0278\n",
      "Epoch 981/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.2766e-06 - acc: 0.4427 - val_loss: 8.7464 - val_acc: 0.0278\n",
      "Epoch 982/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.2444e-06 - acc: 0.4427 - val_loss: 8.7600 - val_acc: 0.0278\n",
      "Epoch 983/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.4032e-06 - acc: 0.4427 - val_loss: 8.8517 - val_acc: 0.0278\n",
      "Epoch 984/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2754e-06 - acc: 0.4427 - val_loss: 8.8740 - val_acc: 0.0278\n",
      "Epoch 985/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.3756e-06 - acc: 0.4427 - val_loss: 8.8088 - val_acc: 0.0278\n",
      "Epoch 986/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.2574e-06 - acc: 0.4427 - val_loss: 8.8329 - val_acc: 0.0278\n",
      "Epoch 987/1000\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 2.2327e-06 - acc: 0.4427 - val_loss: 8.7380 - val_acc: 0.0278\n",
      "Epoch 988/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2365e-06 - acc: 0.4427 - val_loss: 8.8368 - val_acc: 0.0278\n",
      "Epoch 989/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1983e-06 - acc: 0.4427 - val_loss: 8.7605 - val_acc: 0.0278\n",
      "Epoch 990/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2438e-06 - acc: 0.4427 - val_loss: 8.8093 - val_acc: 0.0278\n",
      "Epoch 991/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1771e-06 - acc: 0.4427 - val_loss: 8.8084 - val_acc: 0.0278\n",
      "Epoch 992/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1655e-06 - acc: 0.4427 - val_loss: 8.8102 - val_acc: 0.0278\n",
      "Epoch 993/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1610e-06 - acc: 0.4427 - val_loss: 8.8030 - val_acc: 0.0278\n",
      "Epoch 994/1000\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 2.1516e-06 - acc: 0.4427 - val_loss: 8.8148 - val_acc: 0.0278\n",
      "Epoch 995/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1477e-06 - acc: 0.4427 - val_loss: 8.8135 - val_acc: 0.0278\n",
      "Epoch 996/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1467e-06 - acc: 0.4427 - val_loss: 8.7850 - val_acc: 0.0278\n",
      "Epoch 997/1000\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 2.1400e-06 - acc: 0.4427 - val_loss: 8.7704 - val_acc: 0.0278\n",
      "Epoch 998/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1462e-06 - acc: 0.4427 - val_loss: 8.7875 - val_acc: 0.0278\n",
      "Epoch 999/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.1250e-06 - acc: 0.4427 - val_loss: 8.7656 - val_acc: 0.0278\n",
      "Epoch 1000/1000\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 2.2162e-06 - acc: 0.4427 - val_loss: 8.7927 - val_acc: 0.0278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x267fdb11208>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          #batch_size=80,\n",
    "          epochs=20,\n",
    "          validation_split=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 383, 300)          115200    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 50), (None, 50),  70200     \n",
      "=================================================================\n",
      "Total params: 185,400\n",
      "Trainable params: 185,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = encoder_input_data[1031: 1032]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 52):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'i dislike you'\n",
    "for t, word in enumerate(test.split()):\n",
    "    predict_encoder_data[0, t] = input_token_index[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' నువ్వు బాగోలేదని విన్నాను _END'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(predict_encoder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: definitely!\n",
      "Decoded sentence:  తప్పకుండా _END\n",
      "-\n",
      "Input sentence: he hung up.\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: i ran home.\n",
      "Decoded sentence:  నేను ఇంటికి పరిగెత్తాను _END\n",
      "-\n",
      "Input sentence: who are we?\n",
      "Decoded sentence:  మేము ఎవరము ? _END\n",
      "-\n",
      "Input sentence: are you mad?\n",
      "Decoded sentence:  కోపమొచ్చిందా ? _END\n",
      "-\n",
      "Input sentence: he touched me.\n",
      "Decoded sentence:  ఈ పెన్సిళ్లు ఒకే రంగులో _END\n",
      "-\n",
      "Input sentence: my head hurts.\n",
      "Decoded sentence:  నాకు గంట మోగటం వినపడింది _END\n",
      "-\n",
      "Input sentence: i drank coffee.\n",
      "Decoded sentence:  నేను కాఫీ తాగాను _END\n",
      "-\n",
      "Input sentence: how tall is she?\n",
      "Decoded sentence:  నువ్వు అది చూసావా ? _END\n",
      "-\n",
      "Input sentence: they're animals.\n",
      "Decoded sentence:  కోపమొచ్చిందా ? _END\n",
      "-\n",
      "Input sentence: can you see that?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i began to speak.\n",
      "Decoded sentence:  నేను మాట్లాడటం మొదలుపెట్టాను _END\n",
      "-\n",
      "Input sentence: i dislike coffee.\n",
      "Decoded sentence:  మేము వినాలని అనుకుంటున్నాం _END\n",
      "-\n",
      "Input sentence: i'm hungry again.\n",
      "Decoded sentence:  నాకు మళ్ళా ఆకలి వేస్తుంది _END\n",
      "-\n",
      "Input sentence: i don't accept it.\n",
      "Decoded sentence:  నేను అంగీకరించను _END\n",
      "-\n",
      "Input sentence: what's in the box?\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: which is your pen?\n",
      "Decoded sentence:  నీ కలం ఏది ? _END\n",
      "-\n",
      "Input sentence: are you feeling ok?\n",
      "Decoded sentence:  అతను పెట్టేసాడు _END\n",
      "-\n",
      "Input sentence: help came too late.\n",
      "Decoded sentence:  అది ఇక్కడ చెయ్యడానికి _END\n",
      "-\n",
      "Input sentence: how are you coming?\n",
      "Decoded sentence:  నువ్వు ఎలా వస్తున్నావ్? _END\n",
      "-\n",
      "Input sentence: i do make mistakes.\n",
      "Decoded sentence:  నేనూ తప్పులు చేస్తాను _END\n",
      "-\n",
      "Input sentence: it wasn't my fault.\n",
      "Decoded sentence:  అది అంత తేలిక కాదు, తెలుసా _END\n",
      "-\n",
      "Input sentence: it's very valuable.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: she's not a doctor.\n",
      "Decoded sentence:  ఆమె వైద్యురాలు కాదు _END\n",
      "-\n",
      "Input sentence: we want to hear it.\n",
      "Decoded sentence:  మేము వినాలని అనుకుంటున్నాం _END\n",
      "-\n",
      "Input sentence: what will you have?\n",
      "Decoded sentence:  నువ్వు ఏమి తీసుకుంటావ్? _END\n",
      "-\n",
      "Input sentence: where was your son?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: more coffee, please.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: tom was very scared.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: what are you saying?\n",
      "Decoded sentence:  నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END\n",
      "-\n",
      "Input sentence: you seem very happy.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i don't know who won.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: i'll be very careful.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i've thought of that.\n",
      "Decoded sentence:  నాకు అది తట్టింది _END\n",
      "-\n",
      "Input sentence: she sat on the bench.\n",
      "Decoded sentence:  ఆమె బల్ల మీద కూర్చుంది . _END\n",
      "-\n",
      "Input sentence: what else i can lose?\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: i don't need anything.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: i heard the bell ring.\n",
      "Decoded sentence:  నాకు గంట మోగటం వినపడింది _END\n",
      "-\n",
      "Input sentence: i heard you were sick.\n",
      "Decoded sentence:  నీకు బాగోలేదని విన్నాను _END\n",
      "-\n",
      "Input sentence: i suggest you do that.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: she's not at home now.\n",
      "Decoded sentence:  నేను ఎన్ని మామిడిపండ్లు కావాలి? _END\n",
      "-\n",
      "Input sentence: the station is nearby.\n",
      "Decoded sentence:  స్టేషన్ దగ్గర్లో వుంది _END\n",
      "-\n",
      "Input sentence: this made me very sad.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: i don't speak japanese.\n",
      "Decoded sentence:  నేను జపనీస్ మాట్లాడను _END\n",
      "-\n",
      "Input sentence: i don't trust that guy.\n",
      "Decoded sentence:  నేను వాడిని నమ్మను _END\n",
      "-\n",
      "Input sentence: let's take that chance.\n",
      "Decoded sentence:  మనం ఆ అవకాశం తీసుకుందాం _END\n",
      "-\n",
      "Input sentence: old people walk slowly.\n",
      "Decoded sentence:  ముసలివాళ్లు నెమ్మదిగా నడుస్తారు _END\n",
      "-\n",
      "Input sentence: she was pale with fear.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: there was nothing left.\n",
      "Decoded sentence:  ఇంకేమి మిగల్లేదు _END\n",
      "-\n",
      "Input sentence: this is not a sentence.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: was it really that bad?\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: can i make a phone call?\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: he didn't keep his word.\n",
      "Decoded sentence:  అతను పిల్లలకి స్పానిష్ నేర్పుతున్నాడు _END\n",
      "-\n",
      "Input sentence: he made her a bookshelf.\n",
      "Decoded sentence:  అతడు స్త్రీలాగా వస్త్రాలను ధరించాడు. _END\n",
      "-\n",
      "Input sentence: it's not all your fault.\n",
      "Decoded sentence:  నీ కలం ఏది ? _END\n",
      "-\n",
      "Input sentence: she scared the cat away.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: the work is almost done.\n",
      "Decoded sentence:  చలనచిత్రం మొదలు అవ్వబోతుంది _END\n",
      "-\n",
      "Input sentence: what's your room number?\n",
      "Decoded sentence:  అది ఇక్కడ చెయ్యడానికి నాకు అనుమతి లేదు _END\n",
      "-\n",
      "Input sentence: he dressed up as a woman.\n",
      "Decoded sentence:  అతడు తన చేతులకి అంటిన రక్తాన్ని కడిగేసాడు _END\n",
      "-\n",
      "Input sentence: i'll let it go this time.\n",
      "Decoded sentence:  నేను ఇంటికి పరిగెత్తాను _END\n",
      "-\n",
      "Input sentence: none of them are present.\n",
      "Decoded sentence:  వాళ్లెవరు రాలేదు _END\n",
      "-\n",
      "Input sentence: we did that deliberately.\n",
      "Decoded sentence:  మేము అది కావాలని చేశాం _END\n",
      "-\n",
      "Input sentence: we haven't slept in days.\n",
      "Decoded sentence:  మేము రోజుల తరబడి నిద్రపోలేదు _END\n",
      "-\n",
      "Input sentence: you have to come at once.\n",
      "Decoded sentence:  నువ్వు ఒక్కసారిగా రావాలి _END\n",
      "-\n",
      "Input sentence: out of sight, out of mind.\n",
      "Decoded sentence:  చూపుకి వెలుపల​, మనసుకి వెలుపల​ _END\n",
      "-\n",
      "Input sentence: when did you quit smoking?\n",
      "Decoded sentence:  పొగ తాగడం ఎప్పుడు ఆపేశావ్? _END\n",
      "-\n",
      "Input sentence: where did you put my book?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: you've arrived very early.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: brush your teeth every day.\n",
      "Decoded sentence:  నీ పళ్ళు రోజూ తోముకో _END\n",
      "-\n",
      "Input sentence: did all this really happen?\n",
      "Decoded sentence:  ఇది చెయ్యడానికి సిద్దంగా వున్నావా _END\n",
      "-\n",
      "Input sentence: some of the dogs are alive.\n",
      "Decoded sentence:  కొన్ని కుక్కలు బ్రతికే ఉన్నాయి _END\n",
      "-\n",
      "Input sentence: that wasn't easy, you know.\n",
      "Decoded sentence:  అది అంత తేలిక కాదు, తెలుసా _END\n",
      "-\n",
      "Input sentence: the movie's about to start.\n",
      "Decoded sentence:  చలనచిత్రం మొదలు అవ్వబోతుంది _END\n",
      "-\n",
      "Input sentence: we don't understand french.\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: are you prepared to do this?\n",
      "Decoded sentence:  ఇది చెయ్యడానికి సిద్దంగా వున్నావా _END\n",
      "-\n",
      "Input sentence: i don't know where they are.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: the baby is crying for milk.\n",
      "Decoded sentence:  పసిపాప పాల కోసం ఏడుస్తుంది _END\n",
      "-\n",
      "Input sentence: we'd better leave her alone.\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: you must stay where you are.\n",
      "Decoded sentence:  నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END\n",
      "-\n",
      "Input sentence: don't interfere with my work.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: how many mangoes do you want?\n",
      "Decoded sentence:  మీకు ఎన్ని మామిడిపండ్లు కావాలి? _END\n",
      "-\n",
      "Input sentence: she breathed in the cold air.\n",
      "Decoded sentence:  నువ్వు అది చూసావా ? _END\n",
      "-\n",
      "Input sentence: she was on her way to school.\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: we need money to do anything.\n",
      "Decoded sentence:  నా తల నొప్పిపుడుతుంది _END\n",
      "-\n",
      "Input sentence: i know you're going to say no.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: it actually isn't that simple.\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: tell me about your daily life.\n",
      "Decoded sentence:  నీ రోజువారీ జీవితం గురించి చెప్పు _END\n",
      "-\n",
      "Input sentence: that sounds really interesting.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n",
      "-\n",
      "Input sentence: there's no reason to be afraid.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: we played basketball yesterday.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: you have no need to be ashamed.\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: you may go swimming or fishing.\n",
      "Decoded sentence:  నువ్వు ఈత కొట్టడానికో లేక చేపలు పట్టడానికో వెళ్ళొచ్చు\n",
      "-\n",
      "Input sentence: you must speak in a loud voice.\n",
      "Decoded sentence:  నువ్వు గట్టిగా మాట్లాడాలి _END\n",
      "-\n",
      "Input sentence: i'm not allowed to do that here.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: my sister is crazy about tennis.\n",
      "Decoded sentence:  మా అక్కకి టెన్నిసంటే పిచ్చి _END\n",
      "-\n",
      "Input sentence: do you live in this neighborhood?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: have you ever had a heart attack?\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: i can't keep you here any longer.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n",
      "-\n",
      "Input sentence: she refuses to say more about it.\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: these pencils are the same color.\n",
      "Decoded sentence:  ఈ పెన్సిళ్లు ఒకే రంగులో ఉన్నాయి _END\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', lines.eng[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = 'Hello world'\n",
    "\n",
    "encoder_input_data[seq_index: seq_index + 1]\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input sentence:', lines.eng[seq_index])\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143., 243., 138.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[2: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "134\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "input_text = []\n",
    "target_input_text = []\n",
    "target_text = []\n",
    "\n",
    "for line in open('tel.txt', encoding='utf-8'):\n",
    "    text = line.split('\\t')\n",
    "    source_text = text[0]\n",
    "    translation = text[1]\n",
    "    \n",
    "    #target_translation = translation+'<eos>'\n",
    "    #target_translation_input = '<sos>'+translation\n",
    "    \n",
    "    input_text.append(source_text)\n",
    "    target_text.append(translation)\n",
    "    target_input_text.append(translation)\n",
    "    \n",
    "    \n",
    "output_input_text = target_input_text\n",
    "output_text = target_text \n",
    "    \n",
    "#target_input_text = target_input_text.insert('<sos>')\n",
    "#target_text = target_text + '<eos>'\n",
    "\n",
    "dummy = []\n",
    "for i in target_input_text:\n",
    "    dummy.append('<sos>'+str(i)+'<eos>')\n",
    "\n",
    "print(len(input_text))\n",
    "print(len(target_input_text))\n",
    "print(len(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input tokenizer\n",
    "tokenizer_input = Tokenizer()\n",
    "tokenizer_input.fit_on_texts(input_text)\n",
    "input_sequences = tokenizer_input.texts_to_sequences(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index = tokenizer_input.word_index\n",
    "len(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 1),\n",
       " ('i', 2),\n",
       " ('to', 3),\n",
       " ('the', 4),\n",
       " ('is', 5),\n",
       " ('that', 6),\n",
       " ('a', 7),\n",
       " ('are', 8),\n",
       " (\"don't\", 9),\n",
       " ('do', 10),\n",
       " ('she', 11),\n",
       " ('he', 12),\n",
       " ('we', 13),\n",
       " ('it', 14),\n",
       " ('was', 15),\n",
       " ('this', 16),\n",
       " ('me', 17),\n",
       " ('my', 18),\n",
       " ('can', 19),\n",
       " ('in', 20),\n",
       " ('your', 21),\n",
       " ('very', 22),\n",
       " ('have', 23),\n",
       " ('about', 24),\n",
       " ('how', 25),\n",
       " (\"i'm\", 26),\n",
       " ('not', 27),\n",
       " ('where', 28),\n",
       " ('know', 29),\n",
       " ('of', 30),\n",
       " ('out', 31),\n",
       " ('for', 32),\n",
       " (\"it's\", 33),\n",
       " ('need', 34),\n",
       " ('really', 35),\n",
       " ('her', 36),\n",
       " ('all', 37),\n",
       " ('did', 38),\n",
       " ('no', 39),\n",
       " ('who', 40),\n",
       " ('coffee', 41),\n",
       " ('speak', 42),\n",
       " ('want', 43),\n",
       " ('what', 44),\n",
       " ('more', 45),\n",
       " ('be', 46),\n",
       " ('anything', 47),\n",
       " ('at', 48),\n",
       " ('made', 49),\n",
       " ('with', 50),\n",
       " ('there', 51),\n",
       " ('as', 52),\n",
       " ('go', 53),\n",
       " ('time', 54),\n",
       " ('when', 55),\n",
       " ('going', 56),\n",
       " ('say', 57),\n",
       " ('here', 58),\n",
       " ('one', 59),\n",
       " ('eat', 60),\n",
       " ('up', 61),\n",
       " ('home', 62),\n",
       " (\"what's\", 63),\n",
       " ('which', 64),\n",
       " ('help', 65),\n",
       " ('came', 66),\n",
       " ('make', 67),\n",
       " (\"wasn't\", 68),\n",
       " ('fault', 69),\n",
       " (\"she's\", 70),\n",
       " ('doctor', 71),\n",
       " ('scared', 72),\n",
       " (\"i'll\", 73),\n",
       " (\"i've\", 74),\n",
       " ('on', 75),\n",
       " ('heard', 76),\n",
       " ('were', 77),\n",
       " ('now', 78),\n",
       " ('trust', 79),\n",
       " ('take', 80),\n",
       " ('people', 81),\n",
       " ('left', 82),\n",
       " ('bad', 83),\n",
       " (\"didn't\", 84),\n",
       " ('keep', 85),\n",
       " ('his', 86),\n",
       " ('cat', 87),\n",
       " ('work', 88),\n",
       " ('room', 89),\n",
       " ('them', 90),\n",
       " ('day', 91),\n",
       " ('happen', 92),\n",
       " ('understand', 93),\n",
       " ('must', 94),\n",
       " ('many', 95),\n",
       " ('way', 96),\n",
       " ('school', 97),\n",
       " (\"you're\", 98),\n",
       " (\"isn't\", 99),\n",
       " ('tell', 100),\n",
       " ('reason', 101),\n",
       " ('afraid', 102),\n",
       " ('or', 103),\n",
       " ('heart', 104),\n",
       " ('these', 105),\n",
       " ('pencils', 106),\n",
       " ('color', 107),\n",
       " ('off', 108),\n",
       " ('usually', 109),\n",
       " ('talk', 110),\n",
       " ('bus', 111),\n",
       " ('stop', 112),\n",
       " ('father', 113),\n",
       " ('and', 114),\n",
       " ('definitely', 115),\n",
       " ('hung', 116),\n",
       " ('ran', 117),\n",
       " ('mad', 118),\n",
       " ('touched', 119),\n",
       " ('head', 120),\n",
       " ('hurts', 121),\n",
       " ('drank', 122),\n",
       " ('tall', 123),\n",
       " (\"they're\", 124),\n",
       " ('animals', 125),\n",
       " ('see', 126),\n",
       " ('began', 127),\n",
       " ('dislike', 128),\n",
       " ('hungry', 129),\n",
       " ('again', 130),\n",
       " ('accept', 131),\n",
       " ('box', 132),\n",
       " ('pen', 133),\n",
       " ('feeling', 134),\n",
       " ('ok', 135),\n",
       " ('too', 136),\n",
       " ('late', 137),\n",
       " ('coming', 138),\n",
       " ('mistakes', 139),\n",
       " ('valuable', 140),\n",
       " ('hear', 141),\n",
       " ('will', 142),\n",
       " ('son', 143),\n",
       " ('please', 144),\n",
       " ('tom', 145),\n",
       " ('saying', 146),\n",
       " ('seem', 147),\n",
       " ('happy', 148),\n",
       " ('won', 149),\n",
       " ('careful', 150),\n",
       " ('thought', 151),\n",
       " ('sat', 152),\n",
       " ('bench', 153),\n",
       " ('else', 154),\n",
       " ('lose', 155),\n",
       " ('bell', 156),\n",
       " ('ring', 157),\n",
       " ('sick', 158),\n",
       " ('suggest', 159),\n",
       " ('station', 160),\n",
       " ('nearby', 161),\n",
       " ('sad', 162),\n",
       " ('japanese', 163),\n",
       " ('guy', 164),\n",
       " (\"let's\", 165),\n",
       " ('chance', 166),\n",
       " ('old', 167),\n",
       " ('walk', 168),\n",
       " ('slowly', 169),\n",
       " ('pale', 170),\n",
       " ('fear', 171),\n",
       " ('nothing', 172),\n",
       " ('sentence', 173),\n",
       " ('phone', 174),\n",
       " ('call', 175),\n",
       " ('word', 176),\n",
       " ('bookshelf', 177),\n",
       " ('away', 178),\n",
       " ('almost', 179),\n",
       " ('done', 180),\n",
       " ('number', 181),\n",
       " ('dressed', 182),\n",
       " ('woman', 183),\n",
       " ('let', 184),\n",
       " ('none', 185),\n",
       " ('present', 186),\n",
       " ('deliberately', 187),\n",
       " (\"haven't\", 188),\n",
       " ('slept', 189),\n",
       " ('days', 190),\n",
       " ('come', 191),\n",
       " ('once', 192),\n",
       " ('sight', 193),\n",
       " ('mind', 194),\n",
       " ('quit', 195),\n",
       " ('smoking', 196),\n",
       " ('put', 197),\n",
       " ('book', 198),\n",
       " (\"you've\", 199),\n",
       " ('arrived', 200),\n",
       " ('early', 201),\n",
       " ('brush', 202),\n",
       " ('teeth', 203),\n",
       " ('every', 204),\n",
       " ('some', 205),\n",
       " ('dogs', 206),\n",
       " ('alive', 207),\n",
       " ('easy', 208),\n",
       " (\"movie's\", 209),\n",
       " ('start', 210),\n",
       " ('french', 211),\n",
       " ('prepared', 212),\n",
       " ('they', 213),\n",
       " ('baby', 214),\n",
       " ('crying', 215),\n",
       " ('milk', 216),\n",
       " (\"we'd\", 217),\n",
       " ('better', 218),\n",
       " ('leave', 219),\n",
       " ('alone', 220),\n",
       " ('stay', 221),\n",
       " ('interfere', 222),\n",
       " ('mangoes', 223),\n",
       " ('breathed', 224),\n",
       " ('cold', 225),\n",
       " ('air', 226),\n",
       " ('money', 227),\n",
       " ('actually', 228),\n",
       " ('simple', 229),\n",
       " ('daily', 230),\n",
       " ('life', 231),\n",
       " ('sounds', 232),\n",
       " ('interesting', 233),\n",
       " (\"there's\", 234),\n",
       " ('played', 235),\n",
       " ('basketball', 236),\n",
       " ('yesterday', 237),\n",
       " ('ashamed', 238),\n",
       " ('may', 239),\n",
       " ('swimming', 240),\n",
       " ('fishing', 241),\n",
       " ('loud', 242),\n",
       " ('voice', 243),\n",
       " ('allowed', 244),\n",
       " ('sister', 245),\n",
       " ('crazy', 246),\n",
       " ('tennis', 247),\n",
       " ('live', 248),\n",
       " ('neighborhood', 249),\n",
       " ('ever', 250),\n",
       " ('had', 251),\n",
       " ('attack', 252),\n",
       " (\"can't\", 253),\n",
       " ('any', 254),\n",
       " ('longer', 255),\n",
       " ('refuses', 256),\n",
       " ('same', 257),\n",
       " ('pretty', 258),\n",
       " ('stupid', 259),\n",
       " ('question', 260),\n",
       " ('hesitate', 261),\n",
       " ('ask', 262),\n",
       " ('washed', 263),\n",
       " ('blood', 264),\n",
       " ('hands', 265),\n",
       " ('sorry', 266),\n",
       " ('last', 267),\n",
       " ('night', 268),\n",
       " ('does', 269),\n",
       " ('taught', 270),\n",
       " ('music', 271),\n",
       " ('thirty', 272),\n",
       " ('years', 273),\n",
       " ('from', 274),\n",
       " ('under', 275),\n",
       " ('desk', 276),\n",
       " ('tonight', 277),\n",
       " ('further', 278),\n",
       " ('right', 279),\n",
       " ('anymore', 280),\n",
       " ('sitting', 281),\n",
       " ('down', 282),\n",
       " ('hire', 283),\n",
       " ('lunch', 284),\n",
       " ('getting', 285),\n",
       " ('next', 286),\n",
       " ('teaching', 287),\n",
       " ('spanish', 288),\n",
       " ('children', 289),\n",
       " ('great', 290),\n",
       " ('poet', 291),\n",
       " ('well', 292),\n",
       " (\"wouldn't\", 293),\n",
       " ('today', 294),\n",
       " ('if', 295),\n",
       " ('asked', 296),\n",
       " ('languages', 297),\n",
       " ('spoke', 298),\n",
       " (\"you'll\", 299),\n",
       " ('prefer', 300),\n",
       " ('blue', 301),\n",
       " ('green', 302),\n",
       " ('breakfast', 303),\n",
       " ('before', 304),\n",
       " ('seven', 305),\n",
       " ('apparent', 306),\n",
       " ('why', 307),\n",
       " ('so', 308),\n",
       " ('angry', 309),\n",
       " (\"should've\", 310),\n",
       " ('been', 311),\n",
       " ('able', 312),\n",
       " ('by', 313),\n",
       " ('myself', 314),\n",
       " ('still', 315),\n",
       " ('something', 316),\n",
       " ('might', 317),\n",
       " ('high', 318),\n",
       " ('socks', 319),\n",
       " ('stretch', 320),\n",
       " ('wash', 321),\n",
       " ('pounding', 322),\n",
       " ('opened', 323),\n",
       " ('door', 324),\n",
       " ('nearest', 325),\n",
       " ('mistake', 326),\n",
       " ('though', 327),\n",
       " ('intend', 328),\n",
       " ('afternoon', 329),\n",
       " ('maybe', 330),\n",
       " ('often', 331),\n",
       " ('falls', 332),\n",
       " ('asleep', 333),\n",
       " ('while', 334),\n",
       " ('watching', 335),\n",
       " ('television', 336),\n",
       " ('has', 337),\n",
       " ('two', 338),\n",
       " ('long', 339),\n",
       " ('other', 340),\n",
       " ('short', 341)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted(input_index.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = max(len(s) for s in input_sequences)\n",
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output tokenizer\n",
    "tokenizer_output = Tokenizer(filters='')\n",
    "tokenizer_output.fit_on_texts(target_input_text + target_text)\n",
    "\n",
    "target_sequences = tokenizer_output.texts_to_sequences(target_text)\n",
    "target_input_sequences = tokenizer_output.texts_to_sequences(target_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_output_length = max(len(s) for s in target_sequences)\n",
    "max_output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input_length = max(len(s) for s in target_input_sequences)\n",
    "target_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#telugu index \n",
    "telugu_tokenizer = Tokenizer()\n",
    "telugu_tokenizer.fit_on_texts(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index = tokenizer_output.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "encoder_inputs = pad_sequences(input_sequences, max_input_length)\n",
    "decoder_inputs = pad_sequences(target_input_sequences, max_output_length, padding='post')\n",
    "decoder_output = pad_sequences(target_sequences, max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 13), (134, 10), (134, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.shape, decoder_inputs.shape, decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'C:/Users/cvenkatanagasatya/Pictures/LazyProgrammer/machine_learning_examples/large_files/glove.6B/glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('',embedding_file), encoding='utf8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300) into shape (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-51a660b3a283>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0membedding_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (300) into shape (100)"
     ]
    }
   ],
   "source": [
    "num_words = len(input_index)+1\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in input_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    embed_size,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length = max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e2cbe447507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_input_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'input_text' is not defined"
     ]
    }
   ],
   "source": [
    "len(input_text), max_input_length, len(output_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_text),\n",
    "    max_input_length,\n",
    "    num_words+1\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 343 is out of bounds for axis 2 with size 343",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-76d133036d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdecoder_targets_one_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 343 is out of bounds for axis 2 with size 343"
     ]
    }
   ],
   "source": [
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_output):\n",
    "    for t, word in enumerate(d):\n",
    "        if word != 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i,d in enumerate(decoder_output):\n",
    "   # print(i)\n",
    "    for t, word in enumerate(d):\n",
    "        test.append(word)\n",
    "        #decoder_target_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "encoder_input = Input(shape=(None, ))\n",
    "embed = embedding_layer(encoder_input)\n",
    "encoder = LSTM(100, return_state = True)\n",
    "encoder_output, h, c = encoder(embed)\n",
    "\n",
    "encoder_states = [h,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, ))\n",
    "embed_decoder = embedding_layer(decoder_input)\n",
    "decoder_lstm = LSTM(100, return_state=True)\n",
    "decoder_target, _, _ = decoder_lstm(embed_decoder, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(max_output_length, activation='softmax')\n",
    "decoder_target = decoder_dense(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 13, 100)      34200       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 100), (None, 80400       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 100), (None, 80400       embedding_3[1][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1010        lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 196,010\n",
      "Trainable params: 196,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107 samples, validate on 27 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[13,3] = 342 is not in [0, 342)\n\t [[Node: embedding_3_1/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_3/embeddings/read, embedding_3_1/Cast, embedding_3/embedding_lookup/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-97a140e68039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           validation_split=0.2)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[13,3] = 342 is not in [0, 342)\n\t [[Node: embedding_3_1/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_3/embeddings/read, embedding_3_1/Cast, embedding_3/embedding_lookup/axis)]]"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_inputs, decoder_inputs], decoder_output,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflowproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
