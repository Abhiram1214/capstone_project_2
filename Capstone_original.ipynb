{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import RNN, GRU, LSTM, Dense, Input, Embedding, Dropout, Activation, concatenate\n",
    "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "dimensions = 200\n",
    "num_samples = 10000\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Definitely!</td>\n",
       "      <td>తప్పకుండా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He hung up.</td>\n",
       "      <td>అతను పెట్టేసాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ran home.</td>\n",
       "      <td>నేను ఇంటికి పరిగెత్తాను</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are we?</td>\n",
       "      <td>మేము ఎవరము ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are you mad?</td>\n",
       "      <td>కోపమొచ్చిందా ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Can you tell me where the nearest bus stop is?</td>\n",
       "      <td>దగ్గరలో వున్న బస్ స్టాప్ ఎక్కడో కొంచెం చెప్తావా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>I've made a mistake, though I didn't intend to.</td>\n",
       "      <td>నేనో పొరపాటు చేసాను, కావాలని కాకపోయినా.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>It's going to take all afternoon and maybe more.</td>\n",
       "      <td>మధ్యాహ్నం మొత్తం లేదా ఇంకా ఎక్కువ సమయం పట్టొచ్చు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>My father often falls asleep while watching te...</td>\n",
       "      <td>మా నాన్న దురదర్శిని చూస్తూనే నిద్ర పోతాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>He has two pencils. One is long and the other ...</td>\n",
       "      <td>తన దగ్గర రెండు పెన్సిళ్ళు వున్నాయి. ఒకటి పొడుగ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   eng  \\\n",
       "0                                          Definitely!   \n",
       "1                                          He hung up.   \n",
       "2                                          I ran home.   \n",
       "3                                          Who are we?   \n",
       "4                                         Are you mad?   \n",
       "..                                                 ...   \n",
       "129     Can you tell me where the nearest bus stop is?   \n",
       "130    I've made a mistake, though I didn't intend to.   \n",
       "131   It's going to take all afternoon and maybe more.   \n",
       "132  My father often falls asleep while watching te...   \n",
       "133  He has two pencils. One is long and the other ...   \n",
       "\n",
       "                                                   tel  \n",
       "0                                            తప్పకుండా  \n",
       "1                                      అతను పెట్టేసాడు  \n",
       "2                              నేను ఇంటికి పరిగెత్తాను  \n",
       "3                                         మేము ఎవరము ?  \n",
       "4                                       కోపమొచ్చిందా ?  \n",
       "..                                                 ...  \n",
       "129    దగ్గరలో వున్న బస్ స్టాప్ ఎక్కడో కొంచెం చెప్తావా  \n",
       "130            నేనో పొరపాటు చేసాను, కావాలని కాకపోయినా.  \n",
       "131   మధ్యాహ్నం మొత్తం లేదా ఇంకా ఎక్కువ సమయం పట్టొచ్చు  \n",
       "132          మా నాన్న దురదర్శిని చూస్తూనే నిద్ర పోతాడు  \n",
       "133  తన దగ్గర రెండు పెన్సిళ్ళు వున్నాయి. ఒకటి పొడుగ...  \n",
       "\n",
       "[134 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines= pd.read_table('tel.txt', names=['eng', 'tel'], index_col=False)\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng = lines.eng.apply(lambda x : x.lower())\n",
    "lines.tel = lines.tel.apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "lines.eng = [x for x in lines.eng if x not in string.punctuation]\n",
    "lines.tel = [x for x in lines.tel if x not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definitely!</td>\n",
       "      <td>తప్పకుండా</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he hung up.</td>\n",
       "      <td>అతను పెట్టేసాడు</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ran home.</td>\n",
       "      <td>నేను ఇంటికి పరిగెత్తాను</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are we?</td>\n",
       "      <td>మేము ఎవరము ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are you mad?</td>\n",
       "      <td>కోపమొచ్చిందా ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eng                      tel\n",
       "0   definitely!                తప్పకుండా\n",
       "1   he hung up.          అతను పెట్టేసాడు\n",
       "2   i ran home.  నేను ఇంటికి పరిగెత్తాను\n",
       "3   who are we?             మేము ఎవరము ?\n",
       "4  are you mad?           కోపమొచ్చిందా ?"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.tel = lines.tel.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>tel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>definitely!</td>\n",
       "      <td>START_ తప్పకుండా _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he hung up.</td>\n",
       "      <td>START_ అతను పెట్టేసాడు _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i ran home.</td>\n",
       "      <td>START_ నేను ఇంటికి పరిగెత్తాను _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are we?</td>\n",
       "      <td>START_ మేము ఎవరము ? _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are you mad?</td>\n",
       "      <td>START_ కోపమొచ్చిందా ? _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eng                                  tel\n",
       "0   definitely!                START_ తప్పకుండా _END\n",
       "1   he hung up.          START_ అతను పెట్టేసాడు _END\n",
       "2   i ran home.  START_ నేను ఇంటికి పరిగెత్తాను _END\n",
       "3   who are we?             START_ మేము ఎవరము ? _END\n",
       "4  are you mad?           START_ కోపమొచ్చిందా ? _END"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_tel_words=set()\n",
    "for fr in lines.tel:\n",
    "    for word in fr.split():\n",
    "        if word not in all_tel_words:\n",
    "            all_tel_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 403)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len( all_tel_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_tel_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_tel_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383, 403)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_eng_length = []\n",
    "for word in lines.eng:\n",
    "    #print(word)\n",
    "    max_eng_length.append(len(word.split(\" \")))\n",
    "    \n",
    "np.max(max_eng_length)\n",
    "\n",
    "\n",
    "max_tel_length = []\n",
    "for tel in lines.tel:\n",
    "    #print(word)\n",
    "    max_tel_length.append(len(tel.split(\" \")))\n",
    "    \n",
    "np.max(max_tel_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 12)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(max_eng_length), np.max(max_tel_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index['definitely!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer(filters='')\n",
    "eng_tokenizer.fit_on_texts(lines.eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = eng_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i['definitely!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(lines.eng), 13),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(lines.tel), 12),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(lines.tel), 12, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.tel)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 13), (134, 12, 403))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [123., 140., 340.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rough \n",
    "for i, (eng, tel) in enumerate(zip(lines.eng, lines.tel)):\n",
    "    for t, word in enumerate(eng.split()):\n",
    "        #print(t)\n",
    "        encoder_input_data[i,t] = w2i[word]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data[1,2] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 6., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "en_x=  Embedding(num_encoder_tokens, 50)(encoder_inputs)\n",
    "encoder = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "dex=  Embedding(num_decoder_tokens, 50)\n",
    "final_dex= dex(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     19150       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     20150       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50), (None,  20200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 403)    20553       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 100,253\n",
      "Trainable params: 100,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131 samples, validate on 3 samples\n",
      "Epoch 1/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5739 - acc: 0.3658 - val_loss: 7.3078 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5623 - acc: 0.3651 - val_loss: 7.2600 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5463 - acc: 0.3677 - val_loss: 7.2776 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5393 - acc: 0.3690 - val_loss: 7.2751 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.5311 - acc: 0.3670 - val_loss: 7.2159 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5230 - acc: 0.3702 - val_loss: 7.1928 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5149 - acc: 0.3696 - val_loss: 7.2500 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.5113 - acc: 0.3690 - val_loss: 7.2120 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5024 - acc: 0.3715 - val_loss: 7.1977 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.5184 - acc: 0.3645 - val_loss: 7.1397 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.4969 - acc: 0.3696 - val_loss: 7.1137 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4865 - acc: 0.3747 - val_loss: 7.1784 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4859 - acc: 0.3721 - val_loss: 7.1107 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4780 - acc: 0.3715 - val_loss: 7.0735 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4789 - acc: 0.3715 - val_loss: 7.1893 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4714 - acc: 0.3696 - val_loss: 7.1193 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4647 - acc: 0.3728 - val_loss: 7.0628 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4603 - acc: 0.3760 - val_loss: 7.0652 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4563 - acc: 0.3753 - val_loss: 7.0501 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4533 - acc: 0.3740 - val_loss: 7.0632 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4478 - acc: 0.3740 - val_loss: 7.0407 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4608 - acc: 0.3664 - val_loss: 7.0358 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4381 - acc: 0.3760 - val_loss: 7.0771 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4333 - acc: 0.3810 - val_loss: 6.9550 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4423 - acc: 0.3740 - val_loss: 6.8544 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4260 - acc: 0.3766 - val_loss: 7.0640 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4228 - acc: 0.3779 - val_loss: 6.9296 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4240 - acc: 0.3785 - val_loss: 6.9974 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4160 - acc: 0.3753 - val_loss: 7.0623 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4110 - acc: 0.3772 - val_loss: 7.0176 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4127 - acc: 0.3747 - val_loss: 6.9381 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.4126 - acc: 0.3753 - val_loss: 6.9225 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3995 - acc: 0.3798 - val_loss: 6.9419 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3983 - acc: 0.3785 - val_loss: 6.9086 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3918 - acc: 0.3798 - val_loss: 6.9340 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3908 - acc: 0.3817 - val_loss: 6.9592 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3896 - acc: 0.3785 - val_loss: 6.8970 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3798 - acc: 0.3804 - val_loss: 7.0776 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3784 - acc: 0.3798 - val_loss: 6.9590 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3732 - acc: 0.3842 - val_loss: 7.0476 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3817 - acc: 0.3766 - val_loss: 6.8957 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3666 - acc: 0.3798 - val_loss: 6.8995 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.3823 - val_loss: 6.8308 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3643 - acc: 0.3849 - val_loss: 7.0321 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3605 - acc: 0.3842 - val_loss: 6.9650 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3552 - acc: 0.3855 - val_loss: 6.9967 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3522 - acc: 0.3887 - val_loss: 6.9187 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3492 - acc: 0.3849 - val_loss: 7.0428 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3536 - acc: 0.3842 - val_loss: 7.2078 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3464 - acc: 0.3874 - val_loss: 7.0070 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3405 - acc: 0.3880 - val_loss: 7.1260 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3405 - acc: 0.3849 - val_loss: 7.1065 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3327 - acc: 0.3893 - val_loss: 6.9263 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.3887 - val_loss: 7.0731 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.3868 - val_loss: 6.9947 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3285 - acc: 0.3868 - val_loss: 7.1784 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3214 - acc: 0.3912 - val_loss: 7.0549 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3164 - acc: 0.3919 - val_loss: 7.0532 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3165 - acc: 0.3919 - val_loss: 7.0396 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3166 - acc: 0.3887 - val_loss: 7.1737 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3206 - acc: 0.3868 - val_loss: 6.9328 - val_acc: 0.0278\n",
      "Epoch 62/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3088 - acc: 0.3925 - val_loss: 7.1514 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3099 - acc: 0.3874 - val_loss: 7.0442 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3026 - acc: 0.3925 - val_loss: 6.9368 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2997 - acc: 0.3912 - val_loss: 7.2428 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.3071 - acc: 0.3912 - val_loss: 6.9864 - val_acc: 0.0278\n",
      "Epoch 67/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2974 - acc: 0.3938 - val_loss: 7.0884 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2932 - acc: 0.3976 - val_loss: 7.1037 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2904 - acc: 0.3950 - val_loss: 7.0625 - val_acc: 0.0278\n",
      "Epoch 70/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2898 - acc: 0.3963 - val_loss: 7.2416 - val_acc: 0.0278\n",
      "Epoch 71/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2949 - acc: 0.3893 - val_loss: 7.2695 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2911 - acc: 0.3931 - val_loss: 7.0448 - val_acc: 0.0278\n",
      "Epoch 73/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2815 - acc: 0.3944 - val_loss: 7.1823 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2781 - acc: 0.3957 - val_loss: 7.0867 - val_acc: 0.0278\n",
      "Epoch 75/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2766 - acc: 0.3976 - val_loss: 7.1875 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2749 - acc: 0.3957 - val_loss: 7.1697 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2743 - acc: 0.3969 - val_loss: 7.2221 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2736 - acc: 0.3957 - val_loss: 7.2699 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2797 - acc: 0.3912 - val_loss: 7.2175 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "131/131 [==============================] - 0s 2ms/step - loss: 0.2661 - acc: 0.3976 - val_loss: 7.1718 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2645 - acc: 0.3963 - val_loss: 7.1135 - val_acc: 0.0278\n",
      "Epoch 82/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2625 - acc: 0.4014 - val_loss: 7.1583 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2655 - acc: 0.3950 - val_loss: 7.2243 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2619 - acc: 0.3982 - val_loss: 7.3114 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2614 - acc: 0.3982 - val_loss: 7.0850 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "131/131 [==============================] - 1s 5ms/step - loss: 0.2576 - acc: 0.3969 - val_loss: 7.3179 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2543 - acc: 0.3969 - val_loss: 7.2207 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2525 - acc: 0.3995 - val_loss: 7.2206 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2505 - acc: 0.3989 - val_loss: 7.2406 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2503 - acc: 0.4008 - val_loss: 7.2827 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2451 - acc: 0.4014 - val_loss: 7.3613 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2455 - acc: 0.4020 - val_loss: 7.3624 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2534 - acc: 0.3976 - val_loss: 7.2577 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2395 - acc: 0.4027 - val_loss: 7.3373 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2370 - acc: 0.4020 - val_loss: 7.2939 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.2385 - acc: 0.4014 - val_loss: 7.3120 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2345 - acc: 0.4039 - val_loss: 7.3197 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2334 - acc: 0.4014 - val_loss: 7.2508 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2351 - acc: 0.4008 - val_loss: 7.2867 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2307 - acc: 0.4039 - val_loss: 7.1751 - val_acc: 0.0278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x264e05f33c8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          #batch_size=80,\n",
    "          epochs=100,\n",
    "          validation_split=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 50)          19150     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 39,350\n",
      "Trainable params: 39,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = encoder_input_data[1031: 1032]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 52):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: definitely!\n",
      "Decoded sentence:  తప్పకుండా _END\n",
      "-\n",
      "Input sentence: he hung up.\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: i ran home.\n",
      "Decoded sentence:  నేను ఇంటికి పరిగెత్తాను _END\n",
      "-\n",
      "Input sentence: who are we?\n",
      "Decoded sentence:  మేము ఎవరము ? _END\n",
      "-\n",
      "Input sentence: are you mad?\n",
      "Decoded sentence:  కోపమొచ్చిందా ? _END\n",
      "-\n",
      "Input sentence: he touched me.\n",
      "Decoded sentence:  ఈ పెన్సిళ్లు ఒకే రంగులో _END\n",
      "-\n",
      "Input sentence: my head hurts.\n",
      "Decoded sentence:  నాకు గంట మోగటం వినపడింది _END\n",
      "-\n",
      "Input sentence: i drank coffee.\n",
      "Decoded sentence:  నేను కాఫీ తాగాను _END\n",
      "-\n",
      "Input sentence: how tall is she?\n",
      "Decoded sentence:  నువ్వు అది చూసావా ? _END\n",
      "-\n",
      "Input sentence: they're animals.\n",
      "Decoded sentence:  కోపమొచ్చిందా ? _END\n",
      "-\n",
      "Input sentence: can you see that?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i began to speak.\n",
      "Decoded sentence:  నేను మాట్లాడటం మొదలుపెట్టాను _END\n",
      "-\n",
      "Input sentence: i dislike coffee.\n",
      "Decoded sentence:  మేము వినాలని అనుకుంటున్నాం _END\n",
      "-\n",
      "Input sentence: i'm hungry again.\n",
      "Decoded sentence:  నాకు మళ్ళా ఆకలి వేస్తుంది _END\n",
      "-\n",
      "Input sentence: i don't accept it.\n",
      "Decoded sentence:  నేను అంగీకరించను _END\n",
      "-\n",
      "Input sentence: what's in the box?\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: which is your pen?\n",
      "Decoded sentence:  నీ కలం ఏది ? _END\n",
      "-\n",
      "Input sentence: are you feeling ok?\n",
      "Decoded sentence:  అతను పెట్టేసాడు _END\n",
      "-\n",
      "Input sentence: help came too late.\n",
      "Decoded sentence:  అది ఇక్కడ చెయ్యడానికి _END\n",
      "-\n",
      "Input sentence: how are you coming?\n",
      "Decoded sentence:  నువ్వు ఎలా వస్తున్నావ్? _END\n",
      "-\n",
      "Input sentence: i do make mistakes.\n",
      "Decoded sentence:  నేనూ తప్పులు చేస్తాను _END\n",
      "-\n",
      "Input sentence: it wasn't my fault.\n",
      "Decoded sentence:  అది అంత తేలిక కాదు, తెలుసా _END\n",
      "-\n",
      "Input sentence: it's very valuable.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: she's not a doctor.\n",
      "Decoded sentence:  ఆమె వైద్యురాలు కాదు _END\n",
      "-\n",
      "Input sentence: we want to hear it.\n",
      "Decoded sentence:  మేము వినాలని అనుకుంటున్నాం _END\n",
      "-\n",
      "Input sentence: what will you have?\n",
      "Decoded sentence:  నువ్వు ఏమి తీసుకుంటావ్? _END\n",
      "-\n",
      "Input sentence: where was your son?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: more coffee, please.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: tom was very scared.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: what are you saying?\n",
      "Decoded sentence:  నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END\n",
      "-\n",
      "Input sentence: you seem very happy.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i don't know who won.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: i'll be very careful.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: i've thought of that.\n",
      "Decoded sentence:  నాకు అది తట్టింది _END\n",
      "-\n",
      "Input sentence: she sat on the bench.\n",
      "Decoded sentence:  ఆమె బల్ల మీద కూర్చుంది . _END\n",
      "-\n",
      "Input sentence: what else i can lose?\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: i don't need anything.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: i heard the bell ring.\n",
      "Decoded sentence:  నాకు గంట మోగటం వినపడింది _END\n",
      "-\n",
      "Input sentence: i heard you were sick.\n",
      "Decoded sentence:  నీకు బాగోలేదని విన్నాను _END\n",
      "-\n",
      "Input sentence: i suggest you do that.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: she's not at home now.\n",
      "Decoded sentence:  నేను ఎన్ని మామిడిపండ్లు కావాలి? _END\n",
      "-\n",
      "Input sentence: the station is nearby.\n",
      "Decoded sentence:  స్టేషన్ దగ్గర్లో వుంది _END\n",
      "-\n",
      "Input sentence: this made me very sad.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: i don't speak japanese.\n",
      "Decoded sentence:  నేను జపనీస్ మాట్లాడను _END\n",
      "-\n",
      "Input sentence: i don't trust that guy.\n",
      "Decoded sentence:  నేను వాడిని నమ్మను _END\n",
      "-\n",
      "Input sentence: let's take that chance.\n",
      "Decoded sentence:  మనం ఆ అవకాశం తీసుకుందాం _END\n",
      "-\n",
      "Input sentence: old people walk slowly.\n",
      "Decoded sentence:  ముసలివాళ్లు నెమ్మదిగా నడుస్తారు _END\n",
      "-\n",
      "Input sentence: she was pale with fear.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: there was nothing left.\n",
      "Decoded sentence:  ఇంకేమి మిగల్లేదు _END\n",
      "-\n",
      "Input sentence: this is not a sentence.\n",
      "Decoded sentence:  అది చాలా విలువైనది _END\n",
      "-\n",
      "Input sentence: was it really that bad?\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: can i make a phone call?\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: he didn't keep his word.\n",
      "Decoded sentence:  అతను పిల్లలకి స్పానిష్ నేర్పుతున్నాడు _END\n",
      "-\n",
      "Input sentence: he made her a bookshelf.\n",
      "Decoded sentence:  అతడు స్త్రీలాగా వస్త్రాలను ధరించాడు. _END\n",
      "-\n",
      "Input sentence: it's not all your fault.\n",
      "Decoded sentence:  నీ కలం ఏది ? _END\n",
      "-\n",
      "Input sentence: she scared the cat away.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: the work is almost done.\n",
      "Decoded sentence:  చలనచిత్రం మొదలు అవ్వబోతుంది _END\n",
      "-\n",
      "Input sentence: what's your room number?\n",
      "Decoded sentence:  అది ఇక్కడ చెయ్యడానికి నాకు అనుమతి లేదు _END\n",
      "-\n",
      "Input sentence: he dressed up as a woman.\n",
      "Decoded sentence:  అతడు తన చేతులకి అంటిన రక్తాన్ని కడిగేసాడు _END\n",
      "-\n",
      "Input sentence: i'll let it go this time.\n",
      "Decoded sentence:  నేను ఇంటికి పరిగెత్తాను _END\n",
      "-\n",
      "Input sentence: none of them are present.\n",
      "Decoded sentence:  వాళ్లెవరు రాలేదు _END\n",
      "-\n",
      "Input sentence: we did that deliberately.\n",
      "Decoded sentence:  మేము అది కావాలని చేశాం _END\n",
      "-\n",
      "Input sentence: we haven't slept in days.\n",
      "Decoded sentence:  మేము రోజుల తరబడి నిద్రపోలేదు _END\n",
      "-\n",
      "Input sentence: you have to come at once.\n",
      "Decoded sentence:  నువ్వు ఒక్కసారిగా రావాలి _END\n",
      "-\n",
      "Input sentence: out of sight, out of mind.\n",
      "Decoded sentence:  చూపుకి వెలుపల​, మనసుకి వెలుపల​ _END\n",
      "-\n",
      "Input sentence: when did you quit smoking?\n",
      "Decoded sentence:  పొగ తాగడం ఎప్పుడు ఆపేశావ్? _END\n",
      "-\n",
      "Input sentence: where did you put my book?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: you've arrived very early.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: brush your teeth every day.\n",
      "Decoded sentence:  నీ పళ్ళు రోజూ తోముకో _END\n",
      "-\n",
      "Input sentence: did all this really happen?\n",
      "Decoded sentence:  ఇది చెయ్యడానికి సిద్దంగా వున్నావా _END\n",
      "-\n",
      "Input sentence: some of the dogs are alive.\n",
      "Decoded sentence:  కొన్ని కుక్కలు బ్రతికే ఉన్నాయి _END\n",
      "-\n",
      "Input sentence: that wasn't easy, you know.\n",
      "Decoded sentence:  అది అంత తేలిక కాదు, తెలుసా _END\n",
      "-\n",
      "Input sentence: the movie's about to start.\n",
      "Decoded sentence:  చలనచిత్రం మొదలు అవ్వబోతుంది _END\n",
      "-\n",
      "Input sentence: we don't understand french.\n",
      "Decoded sentence:  మాకు ఫ్రెంచి అర్ధం కాదు _END\n",
      "-\n",
      "Input sentence: are you prepared to do this?\n",
      "Decoded sentence:  ఇది చెయ్యడానికి సిద్దంగా వున్నావా _END\n",
      "-\n",
      "Input sentence: i don't know where they are.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: the baby is crying for milk.\n",
      "Decoded sentence:  పసిపాప పాల కోసం ఏడుస్తుంది _END\n",
      "-\n",
      "Input sentence: we'd better leave her alone.\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: you must stay where you are.\n",
      "Decoded sentence:  నువ్వు ఎక్కడ ఉన్నవో అక్కడే ఉండు _END\n",
      "-\n",
      "Input sentence: don't interfere with my work.\n",
      "Decoded sentence:  నాకు ఏమీ అవసరంలేదు. _END\n",
      "-\n",
      "Input sentence: how many mangoes do you want?\n",
      "Decoded sentence:  మీకు ఎన్ని మామిడిపండ్లు కావాలి? _END\n",
      "-\n",
      "Input sentence: she breathed in the cold air.\n",
      "Decoded sentence:  నువ్వు అది చూసావా ? _END\n",
      "-\n",
      "Input sentence: she was on her way to school.\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: we need money to do anything.\n",
      "Decoded sentence:  నా తల నొప్పిపుడుతుంది _END\n",
      "-\n",
      "Input sentence: i know you're going to say no.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: it actually isn't that simple.\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: tell me about your daily life.\n",
      "Decoded sentence:  నీ రోజువారీ జీవితం గురించి చెప్పు _END\n",
      "-\n",
      "Input sentence: that sounds really interesting.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n",
      "-\n",
      "Input sentence: there's no reason to be afraid.\n",
      "Decoded sentence:  నువ్వు చాల త్వరగా వచ్చావు _END\n",
      "-\n",
      "Input sentence: we played basketball yesterday.\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: you have no need to be ashamed.\n",
      "Decoded sentence:  నువ్వు సిగ్గు పడాల్సిన అవసరం లేదు _END\n",
      "-\n",
      "Input sentence: you may go swimming or fishing.\n",
      "Decoded sentence:  నువ్వు ఈత కొట్టడానికో లేక చేపలు పట్టడానికో వెళ్ళొచ్చు\n",
      "-\n",
      "Input sentence: you must speak in a loud voice.\n",
      "Decoded sentence:  నువ్వు గట్టిగా మాట్లాడాలి _END\n",
      "-\n",
      "Input sentence: i'm not allowed to do that here.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: my sister is crazy about tennis.\n",
      "Decoded sentence:  మా అక్కకి టెన్నిసంటే పిచ్చి _END\n",
      "-\n",
      "Input sentence: do you live in this neighborhood?\n",
      "Decoded sentence:  నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్ _END\n",
      "-\n",
      "Input sentence: have you ever had a heart attack?\n",
      "Decoded sentence:  నేను నువ్వైతే ఈరోజు అక్కడికి వెళ్ళను _END\n",
      "-\n",
      "Input sentence: i can't keep you here any longer.\n",
      "Decoded sentence:  అది ఇక్కడ ఇంకా ఎక్కువ సమయం వుంచలేను _END\n",
      "-\n",
      "Input sentence: she refuses to say more about it.\n",
      "Decoded sentence:  అది అంత సులభం ఏం కాదు _END\n",
      "-\n",
      "Input sentence: these pencils are the same color.\n",
      "Decoded sentence:  ఈ పెన్సిళ్లు ఒకే రంగులో ఉన్నాయి _END\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', lines.eng[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = 'Hello world'\n",
    "\n",
    "encoder_input_data[seq_index: seq_index + 1]\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input sentence:', lines.eng[seq_index])\n",
    "print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143., 243., 138.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[2: 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "134\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "input_text = []\n",
    "target_input_text = []\n",
    "target_text = []\n",
    "\n",
    "for line in open('tel.txt', encoding='utf-8'):\n",
    "    text = line.split('\\t')\n",
    "    source_text = text[0]\n",
    "    translation = text[1]\n",
    "    \n",
    "    #target_translation = translation+'<eos>'\n",
    "    #target_translation_input = '<sos>'+translation\n",
    "    \n",
    "    input_text.append(source_text)\n",
    "    target_text.append(translation)\n",
    "    target_input_text.append(translation)\n",
    "    \n",
    "    \n",
    "output_input_text = target_input_text\n",
    "output_text = target_text \n",
    "    \n",
    "#target_input_text = target_input_text.insert('<sos>')\n",
    "#target_text = target_text + '<eos>'\n",
    "\n",
    "dummy = []\n",
    "for i in target_input_text:\n",
    "    dummy.append('<sos>'+str(i)+'<eos>')\n",
    "\n",
    "print(len(input_text))\n",
    "print(len(target_input_text))\n",
    "print(len(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input tokenizer\n",
    "tokenizer_input = Tokenizer()\n",
    "tokenizer_input.fit_on_texts(input_text)\n",
    "input_sequences = tokenizer_input.texts_to_sequences(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_index = tokenizer_input.word_index\n",
    "len(input_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 1),\n",
       " ('i', 2),\n",
       " ('to', 3),\n",
       " ('the', 4),\n",
       " ('is', 5),\n",
       " ('that', 6),\n",
       " ('a', 7),\n",
       " ('are', 8),\n",
       " (\"don't\", 9),\n",
       " ('do', 10),\n",
       " ('she', 11),\n",
       " ('he', 12),\n",
       " ('we', 13),\n",
       " ('it', 14),\n",
       " ('was', 15),\n",
       " ('this', 16),\n",
       " ('me', 17),\n",
       " ('my', 18),\n",
       " ('can', 19),\n",
       " ('in', 20),\n",
       " ('your', 21),\n",
       " ('very', 22),\n",
       " ('have', 23),\n",
       " ('about', 24),\n",
       " ('how', 25),\n",
       " (\"i'm\", 26),\n",
       " ('not', 27),\n",
       " ('where', 28),\n",
       " ('know', 29),\n",
       " ('of', 30),\n",
       " ('out', 31),\n",
       " ('for', 32),\n",
       " (\"it's\", 33),\n",
       " ('need', 34),\n",
       " ('really', 35),\n",
       " ('her', 36),\n",
       " ('all', 37),\n",
       " ('did', 38),\n",
       " ('no', 39),\n",
       " ('who', 40),\n",
       " ('coffee', 41),\n",
       " ('speak', 42),\n",
       " ('want', 43),\n",
       " ('what', 44),\n",
       " ('more', 45),\n",
       " ('be', 46),\n",
       " ('anything', 47),\n",
       " ('at', 48),\n",
       " ('made', 49),\n",
       " ('with', 50),\n",
       " ('there', 51),\n",
       " ('as', 52),\n",
       " ('go', 53),\n",
       " ('time', 54),\n",
       " ('when', 55),\n",
       " ('going', 56),\n",
       " ('say', 57),\n",
       " ('here', 58),\n",
       " ('one', 59),\n",
       " ('eat', 60),\n",
       " ('up', 61),\n",
       " ('home', 62),\n",
       " (\"what's\", 63),\n",
       " ('which', 64),\n",
       " ('help', 65),\n",
       " ('came', 66),\n",
       " ('make', 67),\n",
       " (\"wasn't\", 68),\n",
       " ('fault', 69),\n",
       " (\"she's\", 70),\n",
       " ('doctor', 71),\n",
       " ('scared', 72),\n",
       " (\"i'll\", 73),\n",
       " (\"i've\", 74),\n",
       " ('on', 75),\n",
       " ('heard', 76),\n",
       " ('were', 77),\n",
       " ('now', 78),\n",
       " ('trust', 79),\n",
       " ('take', 80),\n",
       " ('people', 81),\n",
       " ('left', 82),\n",
       " ('bad', 83),\n",
       " (\"didn't\", 84),\n",
       " ('keep', 85),\n",
       " ('his', 86),\n",
       " ('cat', 87),\n",
       " ('work', 88),\n",
       " ('room', 89),\n",
       " ('them', 90),\n",
       " ('day', 91),\n",
       " ('happen', 92),\n",
       " ('understand', 93),\n",
       " ('must', 94),\n",
       " ('many', 95),\n",
       " ('way', 96),\n",
       " ('school', 97),\n",
       " (\"you're\", 98),\n",
       " (\"isn't\", 99),\n",
       " ('tell', 100),\n",
       " ('reason', 101),\n",
       " ('afraid', 102),\n",
       " ('or', 103),\n",
       " ('heart', 104),\n",
       " ('these', 105),\n",
       " ('pencils', 106),\n",
       " ('color', 107),\n",
       " ('off', 108),\n",
       " ('usually', 109),\n",
       " ('talk', 110),\n",
       " ('bus', 111),\n",
       " ('stop', 112),\n",
       " ('father', 113),\n",
       " ('and', 114),\n",
       " ('definitely', 115),\n",
       " ('hung', 116),\n",
       " ('ran', 117),\n",
       " ('mad', 118),\n",
       " ('touched', 119),\n",
       " ('head', 120),\n",
       " ('hurts', 121),\n",
       " ('drank', 122),\n",
       " ('tall', 123),\n",
       " (\"they're\", 124),\n",
       " ('animals', 125),\n",
       " ('see', 126),\n",
       " ('began', 127),\n",
       " ('dislike', 128),\n",
       " ('hungry', 129),\n",
       " ('again', 130),\n",
       " ('accept', 131),\n",
       " ('box', 132),\n",
       " ('pen', 133),\n",
       " ('feeling', 134),\n",
       " ('ok', 135),\n",
       " ('too', 136),\n",
       " ('late', 137),\n",
       " ('coming', 138),\n",
       " ('mistakes', 139),\n",
       " ('valuable', 140),\n",
       " ('hear', 141),\n",
       " ('will', 142),\n",
       " ('son', 143),\n",
       " ('please', 144),\n",
       " ('tom', 145),\n",
       " ('saying', 146),\n",
       " ('seem', 147),\n",
       " ('happy', 148),\n",
       " ('won', 149),\n",
       " ('careful', 150),\n",
       " ('thought', 151),\n",
       " ('sat', 152),\n",
       " ('bench', 153),\n",
       " ('else', 154),\n",
       " ('lose', 155),\n",
       " ('bell', 156),\n",
       " ('ring', 157),\n",
       " ('sick', 158),\n",
       " ('suggest', 159),\n",
       " ('station', 160),\n",
       " ('nearby', 161),\n",
       " ('sad', 162),\n",
       " ('japanese', 163),\n",
       " ('guy', 164),\n",
       " (\"let's\", 165),\n",
       " ('chance', 166),\n",
       " ('old', 167),\n",
       " ('walk', 168),\n",
       " ('slowly', 169),\n",
       " ('pale', 170),\n",
       " ('fear', 171),\n",
       " ('nothing', 172),\n",
       " ('sentence', 173),\n",
       " ('phone', 174),\n",
       " ('call', 175),\n",
       " ('word', 176),\n",
       " ('bookshelf', 177),\n",
       " ('away', 178),\n",
       " ('almost', 179),\n",
       " ('done', 180),\n",
       " ('number', 181),\n",
       " ('dressed', 182),\n",
       " ('woman', 183),\n",
       " ('let', 184),\n",
       " ('none', 185),\n",
       " ('present', 186),\n",
       " ('deliberately', 187),\n",
       " (\"haven't\", 188),\n",
       " ('slept', 189),\n",
       " ('days', 190),\n",
       " ('come', 191),\n",
       " ('once', 192),\n",
       " ('sight', 193),\n",
       " ('mind', 194),\n",
       " ('quit', 195),\n",
       " ('smoking', 196),\n",
       " ('put', 197),\n",
       " ('book', 198),\n",
       " (\"you've\", 199),\n",
       " ('arrived', 200),\n",
       " ('early', 201),\n",
       " ('brush', 202),\n",
       " ('teeth', 203),\n",
       " ('every', 204),\n",
       " ('some', 205),\n",
       " ('dogs', 206),\n",
       " ('alive', 207),\n",
       " ('easy', 208),\n",
       " (\"movie's\", 209),\n",
       " ('start', 210),\n",
       " ('french', 211),\n",
       " ('prepared', 212),\n",
       " ('they', 213),\n",
       " ('baby', 214),\n",
       " ('crying', 215),\n",
       " ('milk', 216),\n",
       " (\"we'd\", 217),\n",
       " ('better', 218),\n",
       " ('leave', 219),\n",
       " ('alone', 220),\n",
       " ('stay', 221),\n",
       " ('interfere', 222),\n",
       " ('mangoes', 223),\n",
       " ('breathed', 224),\n",
       " ('cold', 225),\n",
       " ('air', 226),\n",
       " ('money', 227),\n",
       " ('actually', 228),\n",
       " ('simple', 229),\n",
       " ('daily', 230),\n",
       " ('life', 231),\n",
       " ('sounds', 232),\n",
       " ('interesting', 233),\n",
       " (\"there's\", 234),\n",
       " ('played', 235),\n",
       " ('basketball', 236),\n",
       " ('yesterday', 237),\n",
       " ('ashamed', 238),\n",
       " ('may', 239),\n",
       " ('swimming', 240),\n",
       " ('fishing', 241),\n",
       " ('loud', 242),\n",
       " ('voice', 243),\n",
       " ('allowed', 244),\n",
       " ('sister', 245),\n",
       " ('crazy', 246),\n",
       " ('tennis', 247),\n",
       " ('live', 248),\n",
       " ('neighborhood', 249),\n",
       " ('ever', 250),\n",
       " ('had', 251),\n",
       " ('attack', 252),\n",
       " (\"can't\", 253),\n",
       " ('any', 254),\n",
       " ('longer', 255),\n",
       " ('refuses', 256),\n",
       " ('same', 257),\n",
       " ('pretty', 258),\n",
       " ('stupid', 259),\n",
       " ('question', 260),\n",
       " ('hesitate', 261),\n",
       " ('ask', 262),\n",
       " ('washed', 263),\n",
       " ('blood', 264),\n",
       " ('hands', 265),\n",
       " ('sorry', 266),\n",
       " ('last', 267),\n",
       " ('night', 268),\n",
       " ('does', 269),\n",
       " ('taught', 270),\n",
       " ('music', 271),\n",
       " ('thirty', 272),\n",
       " ('years', 273),\n",
       " ('from', 274),\n",
       " ('under', 275),\n",
       " ('desk', 276),\n",
       " ('tonight', 277),\n",
       " ('further', 278),\n",
       " ('right', 279),\n",
       " ('anymore', 280),\n",
       " ('sitting', 281),\n",
       " ('down', 282),\n",
       " ('hire', 283),\n",
       " ('lunch', 284),\n",
       " ('getting', 285),\n",
       " ('next', 286),\n",
       " ('teaching', 287),\n",
       " ('spanish', 288),\n",
       " ('children', 289),\n",
       " ('great', 290),\n",
       " ('poet', 291),\n",
       " ('well', 292),\n",
       " (\"wouldn't\", 293),\n",
       " ('today', 294),\n",
       " ('if', 295),\n",
       " ('asked', 296),\n",
       " ('languages', 297),\n",
       " ('spoke', 298),\n",
       " (\"you'll\", 299),\n",
       " ('prefer', 300),\n",
       " ('blue', 301),\n",
       " ('green', 302),\n",
       " ('breakfast', 303),\n",
       " ('before', 304),\n",
       " ('seven', 305),\n",
       " ('apparent', 306),\n",
       " ('why', 307),\n",
       " ('so', 308),\n",
       " ('angry', 309),\n",
       " (\"should've\", 310),\n",
       " ('been', 311),\n",
       " ('able', 312),\n",
       " ('by', 313),\n",
       " ('myself', 314),\n",
       " ('still', 315),\n",
       " ('something', 316),\n",
       " ('might', 317),\n",
       " ('high', 318),\n",
       " ('socks', 319),\n",
       " ('stretch', 320),\n",
       " ('wash', 321),\n",
       " ('pounding', 322),\n",
       " ('opened', 323),\n",
       " ('door', 324),\n",
       " ('nearest', 325),\n",
       " ('mistake', 326),\n",
       " ('though', 327),\n",
       " ('intend', 328),\n",
       " ('afternoon', 329),\n",
       " ('maybe', 330),\n",
       " ('often', 331),\n",
       " ('falls', 332),\n",
       " ('asleep', 333),\n",
       " ('while', 334),\n",
       " ('watching', 335),\n",
       " ('television', 336),\n",
       " ('has', 337),\n",
       " ('two', 338),\n",
       " ('long', 339),\n",
       " ('other', 340),\n",
       " ('short', 341)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted(input_index.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = max(len(s) for s in input_sequences)\n",
    "max_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output tokenizer\n",
    "tokenizer_output = Tokenizer(filters='')\n",
    "tokenizer_output.fit_on_texts(target_input_text + target_text)\n",
    "\n",
    "target_sequences = tokenizer_output.texts_to_sequences(target_text)\n",
    "target_input_sequences = tokenizer_output.texts_to_sequences(target_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_output_length = max(len(s) for s in target_sequences)\n",
    "max_output_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_input_length = max(len(s) for s in target_input_sequences)\n",
    "target_input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#telugu index \n",
    "telugu_tokenizer = Tokenizer()\n",
    "telugu_tokenizer.fit_on_texts(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index = tokenizer_output.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "encoder_inputs = pad_sequences(input_sequences, max_input_length)\n",
    "decoder_inputs = pad_sequences(target_input_sequences, max_output_length, padding='post')\n",
    "decoder_output = pad_sequences(target_sequences, max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 13), (134, 10), (134, 10))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs.shape, decoder_inputs.shape, decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'C:/Users/cvenkatanagasatya/Pictures/LazyProgrammer/machine_learning_examples/large_files/glove.6B/glove.6B.300d.txt'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('',embedding_file), encoding='utf8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300) into shape (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-51a660b3a283>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0membedding_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (300) into shape (100)"
     ]
    }
   ],
   "source": [
    "num_words = len(input_index)+1\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in input_token_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    embed_size,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length = max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e2cbe447507>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_input_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'input_text' is not defined"
     ]
    }
   ],
   "source": [
    "len(input_text), max_input_length, len(output_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_text),\n",
    "    max_input_length,\n",
    "    num_words+1\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 343 is out of bounds for axis 2 with size 343",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-76d133036d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mdecoder_targets_one_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 343 is out of bounds for axis 2 with size 343"
     ]
    }
   ],
   "source": [
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_output):\n",
    "    for t, word in enumerate(d):\n",
    "        if word != 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i,d in enumerate(decoder_output):\n",
    "   # print(i)\n",
    "    for t, word in enumerate(d):\n",
    "        test.append(word)\n",
    "        #decoder_target_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "encoder_input = Input(shape=(None, ))\n",
    "embed = embedding_layer(encoder_input)\n",
    "encoder = LSTM(100, return_state = True)\n",
    "encoder_output, h, c = encoder(embed)\n",
    "\n",
    "encoder_states = [h,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, ))\n",
    "embed_decoder = embedding_layer(decoder_input)\n",
    "decoder_lstm = LSTM(100, return_state=True)\n",
    "decoder_target, _, _ = decoder_lstm(embed_decoder, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(max_output_length, activation='softmax')\n",
    "decoder_target = decoder_dense(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_input, decoder_input], decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 13, 100)      34200       input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 100), (None, 80400       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 100), (None, 80400       embedding_3[1][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1010        lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 196,010\n",
      "Trainable params: 196,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 107 samples, validate on 27 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[13,3] = 342 is not in [0, 342)\n\t [[Node: embedding_3_1/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_3/embeddings/read, embedding_3_1/Cast, embedding_3/embedding_lookup/axis)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-97a140e68039>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m           validation_split=0.2)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflowproject\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: indices[13,3] = 342 is not in [0, 342)\n\t [[Node: embedding_3_1/embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding_3/embeddings/read, embedding_3_1/Cast, embedding_3/embedding_lookup/axis)]]"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_inputs, decoder_inputs], decoder_output,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflowproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
